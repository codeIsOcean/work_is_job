# ============================================================
# Unit-—Ç–µ—Å—Ç—ã –¥–ª—è –º–æ–¥—É–ª—è Content Filter
# ============================================================
# –≠—Ç–æ—Ç –º–æ–¥—É–ª—å —Ç–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞ –∫–æ–Ω—Ç–µ–Ω—Ç–∞:
# - TextNormalizer: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ (l33tspeak, —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏)
# - WordFilter: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
# - FilterManager: –∫–æ–æ—Ä–¥–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö —Ñ–∏–ª—å—Ç—Ä–æ–≤
# ============================================================

# –ò–º–ø–æ—Ä—Ç pytest –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
import pytest
# –ò–º–ø–æ—Ä—Ç —Ç–∏–ø–æ–≤ aiogram –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è mock-–æ–±—ä–µ–∫—Ç–æ–≤
from aiogram import types
# –ò–º–ø–æ—Ä—Ç unittest.mock –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–≥–ª—É—à–µ–∫
from unittest.mock import MagicMock, AsyncMock

# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ Group –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π
from bot.database.models import Group
# –ò–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π content_filter
from bot.database.models_content_filter import (
    ContentFilterSettings,
    FilterWord,
    FilterWhitelist,
    FilterViolation,
)
# –ò–º–ø–æ—Ä—Ç —Ç–µ—Å—Ç–∏—Ä—É–µ–º—ã—Ö –∫–ª–∞—Å—Å–æ–≤
from bot.services.content_filter.text_normalizer import (
    TextNormalizer,
    get_normalizer,
)
from bot.services.content_filter.word_filter import (
    WordFilter,
    WordMatchResult,
)


# ============================================================
# –¢–ï–°–¢–´ –î–õ–Ø TextNormalizer
# ============================================================

class TestTextNormalizerBasic:
    """–¢–µ—Å—Ç—ã –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ TextNormalizer."""

    # –¢–µ—Å—Ç: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    def test_normalize_empty_text(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –í—ã–∑—ã–≤–∞–µ–º —Å –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π
        result = normalizer.normalize("")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        assert result == ""

    # –¢–µ—Å—Ç: None –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞
    def test_normalize_none_text(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –í—ã–∑—ã–≤–∞–µ–º —Å None
        result = normalizer.normalize(None)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        assert result == ""

    # –¢–µ—Å—Ç: –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ –æ–±—Ñ—É—Å–∫–∞—Ü–∏–∏
    def test_normalize_plain_text(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
        # –í–ê–ñ–ù–û: –ø—Ä–æ–±–µ–ª—ã –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏ —É–¥–∞–ª—è—é—Ç—Å—è –¥–ª—è –ª–æ–≤–ª–∏ "–∫ –æ –∫ –∞ –∏ –Ω"
        result = normalizer.normalize("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä")
        # –ü—Ä–æ–±–µ–ª —É–¥–∞–ª—è–µ—Ç—Å—è (—ç—Ç–æ –æ–∂–∏–¥–∞–µ–º–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
        assert result == "–ø—Ä–∏–≤–µ—Ç–º–∏—Ä"

    # –¢–µ—Å—Ç: –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
    def test_normalize_lowercase(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç —Å –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏
        result = normalizer.normalize("–ü–†–ò–í–ï–¢ –ú–ò–†")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É (–ø—Ä–æ–±–µ–ª —É–¥–∞–ª—è–µ—Ç—Å—è)
        assert result == "–ø—Ä–∏–≤–µ—Ç–º–∏—Ä"


class TestTextNormalizerL33tspeak:
    """–¢–µ—Å—Ç—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ l33tspeak (–∑–∞–º–µ–Ω–∞ —Å–∏–º–≤–æ–ª–æ–≤)."""

    # –¢–µ—Å—Ç: –∑–∞–º–µ–Ω–∞ –ª–∞—Ç–∏–Ω–∏—Ü—ã –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—É (w ‚Üí –≤)
    def test_normalize_latin_w_to_cyrillic(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å –ª–∞—Ç–∏–Ω—Å–∫–æ–π w
        result = normalizer.normalize("w–∏—à–∫–∏")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–º–µ–Ω—É w ‚Üí –≤
        assert result == "–≤–∏—à–∫–∏"

    # –¢–µ—Å—Ç: –∑–∞–º–µ–Ω–∞ —Ü–∏—Ñ—Ä –Ω–∞ –±—É–∫–≤—ã (0 ‚Üí –æ)
    def test_normalize_digit_zero_to_o(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å —Ü–∏—Ñ—Ä–æ–π 0
        result = normalizer.normalize("–∫0–∫–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–º–µ–Ω—É 0 ‚Üí –æ
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: –∑–∞–º–µ–Ω–∞ @ –Ω–∞ –∞
    def test_normalize_at_to_a(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å @
        result = normalizer.normalize("–Ω@—Ä–∫–æ—Ç–∏–∫–∏")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–º–µ–Ω—É @ ‚Üí –∞
        assert result == "–Ω–∞—Ä–∫–æ—Ç–∏–∫–∏"

    # –¢–µ—Å—Ç: –∑–∞–º–µ–Ω–∞ 3 –Ω–∞ –∑
    def test_normalize_digit_3_to_z(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å —Ü–∏—Ñ—Ä–æ–π 3
        result = normalizer.normalize("3–∞–∫–ª–∞–¥–∫–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–º–µ–Ω—É 3 ‚Üí –∑
        assert result == "–∑–∞–∫–ª–∞–¥–∫–∞"

    # –¢–µ—Å—Ç: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∑–∞–º–µ–Ω
    def test_normalize_multiple_replacements(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –∑–∞–º–µ–Ω–∞–º–∏
        result = normalizer.normalize("k0k@1n")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∑–∞–º–µ–Ω—ã: k‚Üí–∫, 0‚Üí–æ, @‚Üí–∞, 1‚Üí–∏, n‚Üí–Ω
        assert result == "–∫–æ–∫–∞–∏–Ω"

    # –¢–µ—Å—Ç: –∑–∞–º–µ–Ω–∞ $ –Ω–∞ —Å
    def test_normalize_dollar_to_s(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å $
        result = normalizer.normalize("$–ø–∞–π—Å")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–º–µ–Ω—É $ ‚Üí —Å
        assert result == "—Å–ø–∞–∏—Å"


class TestTextNormalizerSeparators:
    """–¢–µ—Å—Ç—ã —É–¥–∞–ª–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏."""

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ –¥–µ—Ñ–∏—Å–æ–≤ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
    def test_remove_hyphens_between_letters(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å –¥–µ—Ñ–∏—Å–∞–º–∏
        result = normalizer.normalize("–∫-–æ-–∫-–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –¥–µ—Ñ–∏—Å–æ–≤
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
    def test_remove_dots_between_letters(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å —Ç–æ—á–∫–∞–º–∏
        result = normalizer.normalize("–∫.–æ.–∫.–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–π –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
    def test_remove_underscores_between_letters(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è–º–∏
        result = normalizer.normalize("–∫–æ_–∫–∞_–∏–Ω")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–π
        assert result == "–∫–æ–∫–∞–∏–Ω"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–∏—Ä–µ
    def test_remove_em_dash(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å –¥–ª–∏–Ω–Ω—ã–º —Ç–∏—Ä–µ
        result = normalizer.normalize("–∫–æ‚Äî–∫–∞‚Äî–∏–Ω")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω—ã—Ö —Ç–∏—Ä–µ
        assert result == "–∫–æ–∫–∞–∏–Ω"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ —Å–º–µ—à–∞–Ω–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
    def test_remove_mixed_separators(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å–æ —Å–º–µ—à–∞–Ω–Ω—ã–º–∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è–º–∏
        result = normalizer.normalize("–∫-–æ.–∫_–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
        assert result == "–∫–æ–∫–∞"


class TestTextNormalizerInvisibleChars:
    """–¢–µ—Å—Ç—ã —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ–≤–∏–¥–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤."""

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ Zero Width Space
    def test_remove_zero_width_space(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å Zero Width Space
        result = normalizer.normalize("–∫–æ\u200b–∫–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–≤–∏–¥–∏–º–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ Zero Width Non-Joiner
    def test_remove_zero_width_non_joiner(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å ZWNJ
        result = normalizer.normalize("–∫–æ\u200c–∫–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ Byte Order Mark
    def test_remove_bom(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å BOM
        result = normalizer.normalize("\ufeff–∫–æ–∫–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ BOM
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –Ω–µ–≤–∏–¥–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
    def test_remove_multiple_invisible(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–≤–æ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –Ω–µ–≤–∏–¥–∏–º—ã–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
        result = normalizer.normalize("–∫\u200b–æ\u200c–∫\u200d–∞")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–¥–∞–ª–µ–Ω–∏–µ –≤—Å–µ—Ö –Ω–µ–≤–∏–¥–∏–º—ã—Ö
        assert result == "–∫–æ–∫–∞"


class TestTextNormalizerComplex:
    """–¢–µ—Å—Ç—ã –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (–≤—Å–µ —Ç–µ—Ö–Ω–∏–∫–∏ –≤–º–µ—Å—Ç–µ)."""

    # –¢–µ—Å—Ç: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è l33tspeak –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π
    def test_complex_leet_and_separators(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å–ª–æ–∂–Ω—É—é –æ–±—Ñ—É—Å–∫–∞—Ü–∏—é
        result = normalizer.normalize("k-0-k-@-1-n")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ª–Ω—É—é –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
        assert result == "–∫–æ–∫–∞–∏–Ω"

    # –¢–µ—Å—Ç: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –≤—Å–µ—Ö —Ç–µ—Ö–Ω–∏–∫
    def test_complex_all_techniques(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º: –ª–∞—Ç–∏–Ω–∏—Ü–∞ + —Ü–∏—Ñ—Ä—ã + —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ + –Ω–µ–≤–∏–¥–∏–º—ã–µ
        result = normalizer.normalize("w\u200b1-$-k-1")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é: w‚Üí–≤, 1‚Üí–∏, $‚Üí—Å, k‚Üí–∫, 1‚Üí–∏
        # –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π –∏ –Ω–µ–≤–∏–¥–∏–º—ã—Ö: –≤–∏—Å–∫–∏
        assert result == "–≤–∏—Å–∫–∏"

    # –¢–µ—Å—Ç: —Ä–µ–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä –æ–±—Ñ—É—Å–∫–∞—Ü–∏–∏ –Ω–∞—Ä–∫–æ—Ç–∏–∫–æ–≤
    def test_real_drug_obfuscation(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–π –ø—Ä–∏–º–µ—Ä
        result = normalizer.normalize("3@-–∫-–ª@-–¥–∫@")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ø–æ–ª—É—á–∞–µ–º "–∑–∞–∫–ª–∞–¥–∫–∞"
        assert result == "–∑–∞–∫–ª–∞–¥–∫–∞"


class TestTextNormalizerGetWords:
    """–¢–µ—Å—Ç—ã –¥–ª—è –º–µ—Ç–æ–¥–∞ get_words_from_text."""

    # –¢–µ—Å—Ç: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤ –∏–∑ –ø—Ä–æ—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
    def test_get_words_simple(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞
        # –í–ê–ñ–ù–û: –ø—Ä–æ–±–µ–ª—ã —É–¥–∞–ª—è—é—Ç—Å—è –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏ –¥–ª—è –ª–æ–≤–ª–∏ "–∫ –æ –∫ –∞ –∏ –Ω"
        result = normalizer.get_words_from_text("–ü—Ä–∏–≤–µ—Ç –º–∏—Ä")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–∞ —Å–∫–ª–µ–∏–ª–∏—Å—å (–ø—Ä–æ–±–µ–ª —É–¥–∞–ª—ë–Ω)
        assert len(result) == 1
        assert "–ø—Ä–∏–≤–µ—Ç–º–∏—Ä" in result

    # –¢–µ—Å—Ç: –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å–ª–æ–≤ —Å –æ–±—Ñ—É—Å–∫–∞—Ü–∏–µ–π
    def test_get_words_with_leet(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ —Å l33tspeak
        # –í–ê–ñ–ù–û: ! –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ –∏ (CHAR_MAP), –ø–æ—ç—Ç–æ–º—É "w1—à–∫–∏!" ‚Üí "–≤–∏—à–∫–∏–∏"
        result = normalizer.get_words_from_text("–ü—Ä–∏–≤–µ—Ç w1—à–∫–∏!")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤—Å—ë —Å–∫–ª–µ–∏–ª–æ—Å—å –≤ –æ–¥–Ω–æ —Å–ª–æ–≤–æ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
        # w1—à–∫–∏! ‚Üí –≤–∏—à–∫–∏–∏ (! ‚Üí –∏), –≤—Å—ë —Å–∫–ª–µ–µ–Ω–æ —Å "–ø—Ä–∏–≤–µ—Ç"
        assert "–ø—Ä–∏–≤–µ—Ç–≤–∏—à–∫–∏–∏" in result

    # –¢–µ—Å—Ç: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    def test_get_words_empty(self):
        # –°–æ–∑–¥–∞—ë–º —ç–∫–∑–µ–º–ø–ª—è—Ä –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        normalizer = TextNormalizer()
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–ª–æ–≤–∞ –∏–∑ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        result = normalizer.get_words_from_text("")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ø–∏—Å–æ–∫ –ø—É—Å—Ç
        assert len(result) == 0


class TestGetNormalizerSingleton:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Å–∏–Ω–≥–ª—Ç–æ–Ω–∞ get_normalizer."""

    # –¢–µ—Å—Ç: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ —ç–∫–∑–µ–º–ø–ª—è—Ä
    def test_singleton_returns_same_instance(self):
        # –ü–æ–ª—É—á–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–µ—Ä–≤—ã–π —Ä–∞–∑
        normalizer1 = get_normalizer()
        # –ü–æ–ª—É—á–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –≤—Ç–æ—Ä–æ–π —Ä–∞–∑
        normalizer2 = get_normalizer()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –æ–±—ä–µ–∫—Ç
        assert normalizer1 is normalizer2

    # –¢–µ—Å—Ç: –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä TextNormalizer
    def test_singleton_returns_text_normalizer(self):
        # –ü–æ–ª—É—á–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä
        normalizer = get_normalizer()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø
        assert isinstance(normalizer, TextNormalizer)


class TestTextNormalizerCombiningMarks:
    """–¢–µ—Å—Ç—ã –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è Combining Marks (–∑–∞—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è, –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è)."""

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ –∑–∞—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è (COMBINING LONG STROKE OVERLAY U+0336)
    def test_normalize_strikethrough(self):
        normalizer = TextNormalizer()
        # —àÃ∂uÃ∂—àÃ∂–∫Ã∂uÃ∂ - –∑–∞—á—ë—Ä–∫–Ω—É—Ç—ã–π —Ç–µ–∫—Å—Ç
        text = "\u0448\u0336u\u0336\u0448\u0336\u043a\u0336u\u0336"
        result = normalizer.normalize(text)
        # –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è combining marks –∏ –∑–∞–º–µ–Ω—ã u‚Üí—É: —à—É—à–∫—É
        assert result == "—à—É—à–∫—É"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è —Å–Ω–∏–∑—É (COMBINING DOUBLE MACRON BELOW U+035F)
    def test_normalize_underline_below(self):
        normalizer = TextNormalizer()
        # MÕünÕü - —Å –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ–º —Å–Ω–∏–∑—É
        text = "M\u035fn\u035f"
        result = normalizer.normalize(text)
        # –ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è combining marks: –º–Ω
        assert result == "–º–Ω"

    # –¢–µ—Å—Ç: —É–¥–∞–ª–µ–Ω–∏–µ –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è —Å–≤–µ—Ä—Ö—É (COMBINING DOUBLE MACRON U+035E)
    def test_normalize_overline(self):
        normalizer = TextNormalizer()
        # MÕûnÕû - —Å –ø–æ–¥—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ–º —Å–≤–µ—Ä—Ö—É
        text = "M\u035en\u035e"
        result = normalizer.normalize(text)
        assert result == "–º–Ω"

    # –¢–µ—Å—Ç: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –∑–∞—á—ë—Ä–∫–∏–≤–∞–Ω–∏—è –∏ –¥—Ä—É–≥–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
    def test_normalize_strikethrough_with_leet(self):
        normalizer = TextNormalizer()
        # cÃ∂oÃ∂cÃ∂aÃ∂1Ã∂–Ω - –∫–æ–∫–∞–∏–Ω —Å –∑–∞—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ–º –∏ l33tspeak
        text = "c\u0336o\u0336c\u0336a\u03361\u0336\u043d"
        result = normalizer.normalize(text)
        # c‚Üí—Å, o‚Üí–æ, a‚Üí–∞, 1‚Üí–∏: —Å–æ—Å–∞–∏–Ω
        assert result == "—Å–æ—Å–∞–∏–Ω"


class TestTextNormalizerNFKD:
    """–¢–µ—Å—Ç—ã –¥–ª—è NFKD –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (fullwidth, circled, math symbols)."""

    # –¢–µ—Å—Ç: fullwidth –ª–∞—Ç–∏–Ω–∏—Ü–∞ (ÔΩãÔΩèÔΩãÔΩÅ)
    def test_normalize_fullwidth(self):
        normalizer = TextNormalizer()
        # ÔΩãÔΩèÔΩãÔΩÅ - fullwidth
        text = "\uff4b\uff4f\uff4b\uff41"
        result = normalizer.normalize(text)
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: circled letters (‚ìö‚ìû‚ìö‚ìê)
    def test_normalize_circled(self):
        normalizer = TextNormalizer()
        # ‚ìö‚ìû‚ìö‚ìê - enclosed/circled
        text = "\u24da\u24de\u24da\u24d0"
        result = normalizer.normalize(text)
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: mathematical bold (ùê§ùê®ùê§ùêö)
    def test_normalize_math_bold(self):
        normalizer = TextNormalizer()
        # ùê§ùê®ùê§ùêö - mathematical bold
        text = "\U0001d424\U0001d428\U0001d424\U0001d41a"
        result = normalizer.normalize(text)
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: superscript (·µè·µí·µè·µÉ)
    def test_normalize_superscript(self):
        normalizer = TextNormalizer()
        # ·µè·µí·µè·µÉ - superscript
        text = "\u1d4f\u1d52\u1d4f\u1d43"
        result = normalizer.normalize(text)
        assert result == "–∫–æ–∫–∞"


class TestTextNormalizerSmallCaps:
    """–¢–µ—Å—Ç—ã –¥–ª—è Small Caps (·¥ã·¥è·¥ã·¥Ä)."""

    # –¢–µ—Å—Ç: small caps –±—É–∫–≤—ã
    def test_normalize_small_caps(self):
        normalizer = TextNormalizer()
        # ·¥ã·¥è·¥ã·¥Ä - small caps
        text = "\u1d0b\u1d0f\u1d0b\u1d00"
        result = normalizer.normalize(text)
        assert result == "–∫–æ–∫–∞"

    # –¢–µ—Å—Ç: small caps —Å –æ–±—ã—á–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
    def test_normalize_small_caps_mixed(self):
        normalizer = TextNormalizer()
        # –ü—Ä–∏–≤–µ—Ç ·¥ã·¥è·¥ã·¥Ä
        text = "–ü—Ä–∏–≤–µ—Ç \u1d0b\u1d0f\u1d0b\u1d00"
        result = normalizer.normalize(text)
        assert "–∫–æ–∫–∞" in result


class TestTextNormalizerBlockElements:
    """–¢–µ—Å—Ç—ã –¥–ª—è Block Elements –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–π (‚ñë‚ñí‚ñì)."""

    # –¢–µ—Å—Ç: block elements –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
    def test_normalize_block_separators(self):
        normalizer = TextNormalizer()
        # C‚ñëo‚ñëc‚ñëo - —Å block elements –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
        text = "C\u2591o\u2591c\u2591o"
        result = normalizer.normalize(text)
        # Block elements —É–¥–∞–ª—è—é—Ç—Å—è –∫–∞–∫ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏: —Å–æ—Å–æ
        assert result == "—Å–æ—Å–æ"

    # –¢–µ—Å—Ç: —Ä–∞–∑–Ω—ã–µ block elements
    def test_normalize_various_blocks(self):
        normalizer = TextNormalizer()
        # k‚ñío‚ñìk‚ñàa - —Ä–∞–∑–Ω—ã–µ block elements
        text = "k\u2592o\u2593k\u2588a"
        result = normalizer.normalize(text)
        assert result == "–∫–æ–∫–∞"


class TestTextNormalizerTranslit:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç-–¥–∏–≥—Ä–∞—Ñ–æ–≤ (sh‚Üí—à, ch‚Üí—á)."""

    # –¢–µ—Å—Ç: sh ‚Üí —à
    def test_normalize_translit_sh(self):
        normalizer = TextNormalizer()
        result = normalizer.normalize("shishki")
        assert result == "—à–∏—à–∫–∏"

    # –¢–µ—Å—Ç: ch ‚Üí —á
    def test_normalize_translit_ch(self):
        normalizer = TextNormalizer()
        result = normalizer.normalize("chay")
        assert result == "—á–∞–π"

    # –¢–µ—Å—Ç: zh ‚Üí –∂
    def test_normalize_translit_zh(self):
        normalizer = TextNormalizer()
        result = normalizer.normalize("zhena")
        assert result == "–∂–µ–Ω–∞"

    # –¢–µ—Å—Ç: marochki ‚Üí –º–∞—Ä–æ—á–∫–∏
    def test_normalize_translit_marochki(self):
        normalizer = TextNormalizer()
        result = normalizer.normalize("marochki")
        assert result == "–º–∞—Ä–æ—á–∫–∏"

    # –¢–µ—Å—Ç: kokain ‚Üí –∫–æ–∫–∞–∏–Ω
    def test_normalize_translit_kokain(self):
        normalizer = TextNormalizer()
        result = normalizer.normalize("kokain")
        assert result == "–∫–æ–∫–∞–∏–Ω"

    # –¢–µ—Å—Ç: ekstazi ‚Üí –µ–∫—Å—Ç–∞–∑–∏
    def test_normalize_translit_ekstazi(self):
        normalizer = TextNormalizer()
        result = normalizer.normalize("ekstazi")
        assert result == "–µ–∫—Å—Ç–∞–∑–∏"

    # –¢–µ—Å—Ç: shch ‚Üí —â (—á–µ—Ç—ã—Ä—ë—Ö–±—É–∫–≤–µ–Ω–Ω—ã–π –¥–∏–≥—Ä–∞—Ñ)
    def test_normalize_translit_shch(self):
        normalizer = TextNormalizer()
        result = normalizer.normalize("shchi")
        assert result == "—â–∏"

    # –¢–µ—Å—Ç: ya, yu, yo ‚Üí —è, —é, —ë
    def test_normalize_translit_soft_vowels(self):
        normalizer = TextNormalizer()
        assert normalizer.normalize("ya") == "—è"
        assert normalizer.normalize("yu") == "—é"
        assert normalizer.normalize("yo") == "—ë"

    # –¢–µ—Å—Ç: –∫–æ–º–±–∏–Ω–∞—Ü–∏—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–∞ —Å l33tspeak
    def test_normalize_translit_with_leet(self):
        normalizer = TextNormalizer()
        # sh1shk1 (1‚Üí–∏) ‚Üí —à–∏—à–∫–∏
        result = normalizer.normalize("sh1shk1")
        assert result == "—à–∏—à–∫–∏"

    # –¢–µ—Å—Ç: —Ç—Ä–∞–Ω—Å–ª–∏—Ç —Å –∑–∞—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ–º
    def test_normalize_translit_with_strikethrough(self):
        normalizer = TextNormalizer()
        # MÃ∂aÃ∂rÃ∂oÃ∂cÃ∂hÃ∂kÃ∂iÃ∂ - –º–∞—Ä–æ—á–∫–∏ —Å –∑–∞—á—ë—Ä–∫–∏–≤–∞–Ω–∏–µ–º
        text = "M\u0336a\u0336r\u0336o\u0336c\u0336h\u0336k\u0336i\u0336"
        result = normalizer.normalize(text)
        assert result == "–º–∞—Ä–æ—á–∫–∏"


# ============================================================
# –¢–ï–°–¢–´ –î–õ–Ø WordFilter
# ============================================================

class TestWordMatchResult:
    """–¢–µ—Å—Ç—ã –¥–ª—è –∫–ª–∞—Å—Å–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ WordMatchResult."""

    # –¢–µ—Å—Ç: —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –±–µ–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    def test_no_match_result(self):
        # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        result = WordMatchResult(matched=False)
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–ª–∞–≥
        assert result.matched is False
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª—è None
        assert result.word is None
        assert result.word_id is None

    # –¢–µ—Å—Ç: —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
    def test_match_result(self):
        # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ–º
        result = WordMatchResult(
            matched=True,
            word="—Ç–µ—Å—Ç",
            word_id=123,
            action="mute",
            action_duration=60,
            category="drugs"
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –ø–æ–ª—è
        assert result.matched is True
        assert result.word == "—Ç–µ—Å—Ç"
        assert result.word_id == 123
        assert result.action == "mute"
        assert result.action_duration == 60
        assert result.category == "drugs"


@pytest.mark.asyncio
async def test_word_filter_empty_text(db_session):
    """–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=-1001234567890, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    result = await word_filter.check("", -1001234567890, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
    assert result.matched is False


@pytest.mark.asyncio
async def test_word_filter_no_words_defined(db_session):
    """–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–æ–≥–¥–∞ –Ω–µ—Ç –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã—Ö —Å–ª–æ–≤."""
    # ID —á–∞—Ç–∞
    chat_id = -1001111111111
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç
    result = await word_filter.check("–ª—é–±–æ–π —Ç–µ–∫—Å—Ç", chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è (–Ω–µ—Ç —Å–ª–æ–≤ –≤ –ë–î)
    assert result.matched is False


@pytest.mark.asyncio
async def test_word_filter_word_match(db_session):
    """–¢–µ—Å—Ç –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞."""
    # ID —á–∞—Ç–∞
    chat_id = -1002222222222
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–µ —Å–ª–æ–≤–æ
    await word_filter.add_word(
        chat_id=chat_id,
        word="—Ç–µ—Å—Ç",
        created_by=123456,
        session=db_session,
        match_type='word'
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç —Å —ç—Ç–∏–º —Å–ª–æ–≤–æ–º
    result = await word_filter.check("—ç—Ç–æ —Ç–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏", chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ –Ω–∞–π–¥–µ–Ω–æ
    assert result.matched is True
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞–π–¥–µ–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ
    assert result.word == "—Ç–µ—Å—Ç"


@pytest.mark.asyncio
async def test_word_filter_word_no_match(db_session):
    """–¢–µ—Å—Ç –∫–æ–≥–¥–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."""
    # ID —á–∞—Ç–∞
    chat_id = -1003333333333
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–µ —Å–ª–æ–≤–æ
    await word_filter.add_word(
        chat_id=chat_id,
        word="–∑–∞–ø—Ä–µ—â–µ–Ω–æ",
        created_by=123456,
        session=db_session
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –ë–ï–ó —ç—Ç–æ–≥–æ —Å–ª–æ–≤–∞
    result = await word_filter.check("–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç", chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ –ù–ï –Ω–∞–π–¥–µ–Ω–æ
    assert result.matched is False


@pytest.mark.asyncio
async def test_word_filter_leet_obfuscation(db_session):
    """–¢–µ—Å—Ç –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Å–ª–æ–≤–∞ —Å l33tspeak –æ–±—Ñ—É—Å–∫–∞—Ü–∏–µ–π."""
    # ID —á–∞—Ç–∞
    chat_id = -1004444444444
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–µ —Å–ª–æ–≤–æ –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ
    await word_filter.add_word(
        chat_id=chat_id,
        word="–∫–æ–∫–∞",
        created_by=123456,
        session=db_session
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç —Å l33tspeak –≤–µ—Ä—Å–∏–µ–π (k0ka)
    result = await word_filter.check("–ø—Ä–æ–¥–∞—é k0ka", chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ –Ω–∞–π–¥–µ–Ω–æ –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –æ–±—Ñ—É—Å–∫–∞—Ü–∏—é
    assert result.matched is True


@pytest.mark.asyncio
async def test_word_filter_phrase_match(db_session):
    """–¢–µ—Å—Ç –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Ñ—Ä–∞–∑—ã (phrase match type)."""
    # ID —á–∞—Ç–∞
    chat_id = -1005555555555
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—É—é —Ñ—Ä–∞–∑—É
    await word_filter.add_word(
        chat_id=chat_id,
        word="–∫–æ–∫",
        created_by=123456,
        session=db_session,
        match_type='phrase'  # –ò—â–µ–º –∫–∞–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫—É
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –≥–¥–µ —Ñ—Ä–∞–∑–∞ —á–∞—Å—Ç—å —Å–ª–æ–≤–∞
    result = await word_filter.check("–∫–æ–∫–∞–∏–Ω –ø—Ä–æ–¥–∞—é", chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—Ä–∞–∑–∞ –Ω–∞–π–¥–µ–Ω–∞ (phrase –∏—â–µ—Ç –ø–æ–¥—Å—Ç—Ä–æ–∫—É)
    assert result.matched is True


@pytest.mark.asyncio
async def test_word_filter_add_and_remove_word(db_session):
    """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞."""
    # ID —á–∞—Ç–∞
    chat_id = -1006666666666
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ
    await word_filter.add_word(
        chat_id=chat_id,
        word="—É–¥–∞–ª–∏",
        created_by=123456,
        session=db_session
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ —Ä–∞–±–æ—Ç–∞–µ—Ç
    result1 = await word_filter.check("—Ç–µ–∫—Å—Ç —É–¥–∞–ª–∏ —Ç—É—Ç", chat_id, db_session)
    assert result1.matched is True
    # –£–¥–∞–ª—è–µ–º —Å–ª–æ–≤–æ
    removed = await word_filter.remove_word(chat_id, "—É–¥–∞–ª–∏", db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É–¥–∞–ª–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ
    assert removed is True
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ –±–æ–ª—å—à–µ –Ω–µ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç
    result2 = await word_filter.check("—Ç–µ–∫—Å—Ç —É–¥–∞–ª–∏ —Ç—É—Ç", chat_id, db_session)
    assert result2.matched is False


@pytest.mark.asyncio
async def test_word_filter_remove_nonexistent_word(db_session):
    """–¢–µ—Å—Ç —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞."""
    # ID —á–∞—Ç–∞
    chat_id = -1007777777777
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –ü—ã—Ç–∞–µ–º—Å—è —É–¥–∞–ª–∏—Ç—å –Ω–µ—Å—É—â–µ—Å—Ç–≤—É—é—â–µ–µ —Å–ª–æ–≤–æ
    removed = await word_filter.remove_word(chat_id, "–Ω–µ—Å—É—â–µ—Å—Ç–≤—É–µ—Ç", db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å
    assert removed is False


@pytest.mark.asyncio
async def test_word_filter_get_words_list(db_session):
    """–¢–µ—Å—Ç –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤."""
    # ID —á–∞—Ç–∞
    chat_id = -1008888888888
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ª–æ–≤
    await word_filter.add_word(chat_id, "—Å–ª–æ–≤–æ1", 111, db_session)
    await word_filter.add_word(chat_id, "—Å–ª–æ–≤–æ2", 111, db_session)
    await word_filter.add_word(chat_id, "—Å–ª–æ–≤–æ3", 111, db_session)
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫
    words = await word_filter.get_words_list(chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    assert len(words) == 3


@pytest.mark.asyncio
async def test_word_filter_get_words_count(db_session):
    """–¢–µ—Å—Ç –ø–æ–¥—Å—á—ë—Ç–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤."""
    # ID —á–∞—Ç–∞
    chat_id = -1009999999999
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    count0 = await word_filter.get_words_count(chat_id, db_session)
    assert count0 == 0
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞
    await word_filter.add_word(chat_id, "—Å–ª–æ–≤–æ1", 111, db_session)
    await word_filter.add_word(chat_id, "—Å–ª–æ–≤–æ2", 111, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    count2 = await word_filter.get_words_count(chat_id, db_session)
    assert count2 == 2


@pytest.mark.asyncio
async def test_word_filter_with_action(db_session):
    """–¢–µ—Å—Ç —Å–ª–æ–≤–∞ —Å –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–º –¥–µ–π—Å—Ç–≤–∏–µ–º."""
    # ID —á–∞—Ç–∞
    chat_id = -1010101010101
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ —Å –¥–µ–π—Å—Ç–≤–∏–µ–º mute –Ω–∞ 60 –º–∏–Ω—É—Ç
    await word_filter.add_word(
        chat_id=chat_id,
        word="–º—É—Ç—Å–ª–æ–≤–æ",
        created_by=123456,
        session=db_session,
        action="mute",
        action_duration=60
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç
    result = await word_filter.check("—Ç–µ–∫—Å—Ç –º—É—Ç—Å–ª–æ–≤–æ —Ç—É—Ç", chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    assert result.matched is True
    assert result.action == "mute"
    assert result.action_duration == 60


@pytest.mark.asyncio
async def test_word_filter_with_category(db_session):
    """–¢–µ—Å—Ç —Å–ª–æ–≤–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π."""
    # ID —á–∞—Ç–∞
    chat_id = -1011111111111
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É –¥–ª—è —Ç–µ—Å—Ç–∞
    group = Group(chat_id=chat_id, title="Test Group")
    # –î–æ–±–∞–≤–ª—è–µ–º –≥—Ä—É–ø–ø—É –≤ —Å–µ—Å—Å–∏—é
    db_session.add(group)
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()
    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π
    await word_filter.add_word(
        chat_id=chat_id,
        word="–Ω–∞—Ä–∫–æ—Ç–∏–∫",
        created_by=123456,
        session=db_session,
        category="drugs"
    )
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç
    result = await word_filter.check("–ø—Ä–æ–¥–∞—é –Ω–∞—Ä–∫–æ—Ç–∏–∫", chat_id, db_session)
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
    assert result.matched is True
    assert result.category == "drugs"


# ============================================================
# –¢–ï–°–¢–´ CALLBACK_DATA: –ü–†–û–í–ï–†–ö–ê –õ–ò–ú–ò–¢–ê 64 –ë–ê–ô–¢–ê
# ============================================================

class TestContentFilterCallbackDataLimit:
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —á—Ç–æ callback_data —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç 64 –±–∞–π—Ç–∞."""

    # –¢–µ—Å—Ç: callback –≥–ª–∞–≤–Ω–æ–≥–æ –º–µ–Ω—é
    def test_main_menu_callback_within_limit(self):
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–π chat_id (14 —Ü–∏—Ñ—Ä)
        chat_id = -10023026384650
        # –§–æ—Ä–º–∏—Ä—É–µ–º callback
        callback = f"cf:m:{chat_id}"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        assert len(callback.encode('utf-8')) <= 64

    # –¢–µ—Å—Ç: callback toggle
    def test_toggle_callback_within_limit(self):
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–π chat_id
        chat_id = -10023026384650
        # –§–æ—Ä–º–∏—Ä—É–µ–º callback
        callback = f"cf:toggle:word_filter:{chat_id}"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        assert len(callback.encode('utf-8')) <= 64

    # –¢–µ—Å—Ç: callback –¥–ª—è —Å–ª–æ–≤
    def test_words_callback_within_limit(self):
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–π chat_id
        chat_id = -10023026384650
        # –§–æ—Ä–º–∏—Ä—É–µ–º callback
        callback = f"cf:words:{chat_id}"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        assert len(callback.encode('utf-8')) <= 64

    # –¢–µ—Å—Ç: callback —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞
    def test_delete_word_callback_within_limit(self):
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–π chat_id
        chat_id = -10023026384650
        # –ë–æ–ª—å—à–æ–π ID —Å–ª–æ–≤–∞
        word_id = 999999
        # –§–æ—Ä–º–∏—Ä—É–µ–º callback
        callback = f"cf:wd:{word_id}:{chat_id}"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        assert len(callback.encode('utf-8')) <= 64

    # –¢–µ—Å—Ç: callback —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    def test_sensitivity_callback_within_limit(self):
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–π chat_id
        chat_id = -10023026384650
        # –ó–Ω–∞—á–µ–Ω–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        value = 100
        # –§–æ—Ä–º–∏—Ä—É–µ–º callback
        callback = f"cf:ss:{value}:{chat_id}"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        assert len(callback.encode('utf-8')) <= 64

    # –¢–µ—Å—Ç: callback –¥–µ–π—Å—Ç–≤–∏—è
    def test_action_callback_within_limit(self):
        # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–π chat_id
        chat_id = -10023026384650
        # –°–∞–º–æ–µ –¥–ª–∏–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
        action = "delete"
        # –§–æ—Ä–º–∏—Ä—É–µ–º callback
        callback = f"cf:sa:{action}:{chat_id}"
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É
        assert len(callback.encode('utf-8')) <= 64


# ============================================================
# –ò–ù–¢–ï–ì–†–ê–¶–ò–û–ù–ù–´–ï –¢–ï–°–¢–´: –ü–û–õ–ù–´–ô –¶–ò–ö–õ
# ============================================================

@pytest.mark.asyncio
async def test_full_cycle_add_check_remove_word(db_session):
    """
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç: –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –¥–æ–±–∞–≤–ª–µ–Ω–∏—è, –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞.
    """
    # ID —á–∞—Ç–∞
    chat_id = -1020202020202
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É
    group = Group(chat_id=chat_id, title="Integration Test Group")
    db_session.add(group)
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()

    # –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –±–µ–∑ —Å–ª–æ–≤ –Ω–∏—á–µ–≥–æ –Ω–µ –ª–æ–≤–∏—Ç—Å—è
    result1 = await word_filter.check("—Ç–µ–∫—Å—Ç —Å–æ —Å–ª–æ–≤–æ–º –Ω–∞—Ä–∫–æ—Ç–∏–∫", chat_id, db_session)
    assert result1.matched is False, "–ë–µ–∑ —Å–ª–æ–≤ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π"

    # –®–ê–ì 2: –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ
    word = await word_filter.add_word(
        chat_id=chat_id,
        word="–Ω–∞—Ä–∫–æ—Ç–∏–∫",
        created_by=123,
        session=db_session,
        action="mute",
        action_duration=30
    )
    assert word.id is not None

    # –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ –ª–æ–≤–∏—Ç—Å—è
    result2 = await word_filter.check("—Ç–µ–∫—Å—Ç —Å–æ —Å–ª–æ–≤–æ–º –Ω–∞—Ä–∫–æ—Ç–∏–∫", chat_id, db_session)
    assert result2.matched is True, "–°–ª–æ–≤–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω–æ"
    assert result2.word == "–Ω–∞—Ä–∫–æ—Ç–∏–∫"
    assert result2.action == "mute"
    assert result2.action_duration == 30

    # –®–ê–ì 4: –ü—Ä–æ–≤–µ—Ä—è–µ–º l33tspeak –≤–µ—Ä—Å–∏—é (n@—Ä–∫–æ—Ç–∏–∫)
    result3 = await word_filter.check("–ø—Ä–æ–¥–∞—é n@—Ä–∫0—Ç1–∫", chat_id, db_session)
    # –≠—Ç–æ –¥–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –±–ª–∞–≥–æ–¥–∞—Ä—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
    assert result3.matched is True, "L33tspeak –≤–µ—Ä—Å–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –Ω–∞–π–¥–µ–Ω–∞"

    # –®–ê–ì 5: –£–¥–∞–ª—è–µ–º —Å–ª–æ–≤–æ
    removed = await word_filter.remove_word(chat_id, "–Ω–∞—Ä–∫–æ—Ç–∏–∫", db_session)
    assert removed is True

    # –®–ê–ì 6: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–ª–æ–≤–æ –±–æ–ª—å—à–µ –Ω–µ –ª–æ–≤–∏—Ç—Å—è
    result4 = await word_filter.check("—Ç–µ–∫—Å—Ç —Å–æ —Å–ª–æ–≤–æ–º –Ω–∞—Ä–∫–æ—Ç–∏–∫", chat_id, db_session)
    assert result4.matched is False, "–ü–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –ª–æ–≤–∏—Ç—å—Å—è"


@pytest.mark.asyncio
async def test_multitenant_word_filter(db_session):
    """
    –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç: –º—É–ª—å—Ç–∏—Ç–µ–Ω–∞–Ω—Ç–Ω–æ—Å—Ç—å (—Å–ª–æ–≤–∞ —Ä–∞–∑–Ω—ã—Ö –≥—Ä—É–ø–ø –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è).
    """
    # ID –ø–µ—Ä–≤–æ–π –≥—Ä—É–ø–ø—ã
    chat_id_1 = -1030303030303
    # ID –≤—Ç–æ—Ä–æ–π –≥—Ä—É–ø–ø—ã
    chat_id_2 = -1040404040404
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—ã
    group1 = Group(chat_id=chat_id_1, title="Group 1")
    group2 = Group(chat_id=chat_id_2, title="Group 2")
    db_session.add(group1)
    db_session.add(group2)
    await db_session.commit()
    # –°–æ–∑–¥–∞—ë–º —Ñ–∏–ª—å—Ç—Ä
    word_filter = WordFilter()

    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤—É—é –≥—Ä—É–ø–ø—É
    await word_filter.add_word(chat_id_1, "–∑–∞–ø—Ä–µ—â–µ–Ω–æ1", 111, db_session)

    # –î–æ–±–∞–≤–ª—è–µ–º –¥—Ä—É–≥–æ–µ —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –≤–æ –≤—Ç–æ—Ä—É—é –≥—Ä—É–ø–ø—É
    await word_filter.add_word(chat_id_2, "–∑–∞–ø—Ä–µ—â–µ–Ω–æ2", 222, db_session)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é –≥—Ä—É–ø–ø—É
    result1_in_1 = await word_filter.check("—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–æ1", chat_id_1, db_session)
    assert result1_in_1.matched is True, "–°–ª–æ–≤–æ 1 –¥–æ–ª–∂–Ω–æ –Ω–∞–π—Ç–∏—Å—å –≤ –≥—Ä—É–ø–ø–µ 1"

    result2_in_1 = await word_filter.check("—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–æ2", chat_id_1, db_session)
    assert result2_in_1.matched is False, "–°–ª–æ–≤–æ 2 –ù–ï –¥–æ–ª–∂–Ω–æ –Ω–∞–π—Ç–∏—Å—å –≤ –≥—Ä—É–ø–ø–µ 1"

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ç–æ—Ä—É—é –≥—Ä—É–ø–ø—É
    result1_in_2 = await word_filter.check("—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–æ1", chat_id_2, db_session)
    assert result1_in_2.matched is False, "–°–ª–æ–≤–æ 1 –ù–ï –¥–æ–ª–∂–Ω–æ –Ω–∞–π—Ç–∏—Å—å –≤ –≥—Ä—É–ø–ø–µ 2"

    result2_in_2 = await word_filter.check("—Ç–µ–∫—Å—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–æ2", chat_id_2, db_session)
    assert result2_in_2.matched is True, "–°–ª–æ–≤–æ 2 –¥–æ–ª–∂–Ω–æ –Ω–∞–π—Ç–∏—Å—å –≤ –≥—Ä—É–ø–ø–µ 2"


# ============================================================
# –¢–ï–°–¢–´ –ò–ú–ü–û–†–¢–û–í –ò –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–ò
# ============================================================

class TestContentFilterModuleImports:
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —á—Ç–æ –≤—Å–µ –º–æ–¥—É–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∏–º–ø–æ—Ä—Ç–∏—Ä—É—é—Ç—Å—è."""

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç text_normalizer
    def test_text_normalizer_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å
        from bot.services.content_filter import text_normalizer
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª–∞—Å—Å–æ–≤
        assert hasattr(text_normalizer, 'TextNormalizer')
        assert hasattr(text_normalizer, 'get_normalizer')

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç word_filter
    def test_word_filter_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å
        from bot.services.content_filter import word_filter
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª–∞—Å—Å–æ–≤
        assert hasattr(word_filter, 'WordFilter')
        assert hasattr(word_filter, 'WordMatchResult')

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç filter_manager
    def test_filter_manager_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å
        from bot.services.content_filter import filter_manager
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–ª–∞—Å—Å–æ–≤
        assert hasattr(filter_manager, 'FilterManager')
        assert hasattr(filter_manager, 'FilterResult')

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç –∏–∑ __init__
    def test_content_filter_init_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –≥–ª–∞–≤–Ω–æ–≥–æ –º–æ–¥—É–ª—è
        from bot.services.content_filter import (
            TextNormalizer,
            WordFilter,
            FilterManager,
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–ª–∞—Å—Å—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å
        assert TextNormalizer is not None
        assert WordFilter is not None
        assert FilterManager is not None

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç –º–æ–¥–µ–ª–µ–π
    def test_content_filter_models_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
        from bot.database.models_content_filter import (
            ContentFilterSettings,
            FilterWord,
            FilterWhitelist,
            FilterViolation,
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–µ–π
        assert ContentFilterSettings is not None
        assert FilterWord is not None
        assert FilterWhitelist is not None
        assert FilterViolation is not None

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä
    def test_content_filter_keyboards_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã
        from bot.keyboards.content_filter_keyboards import (
            create_content_filter_main_menu,
            create_content_filter_settings_menu,
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å
        assert callable(create_content_filter_main_menu)
        assert callable(create_content_filter_settings_menu)

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç handlers router
    def test_content_filter_handlers_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–æ—É—Ç–µ—Ä
        from bot.handlers.content_filter import content_filter_router
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ä–æ—É—Ç–µ—Ä —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        assert content_filter_router is not None

    # –¢–µ—Å—Ç: –∏–º–ø–æ—Ä—Ç Phase 2 –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–≤
    def test_phase2_detectors_imports(self):
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –¥–µ—Ç–µ–∫—Ç–æ—Ä—ã –∏–∑ __init__
        from bot.services.content_filter import (
            ScamDetector,
            get_scam_detector,
            FloodDetector,
            create_flood_detector,
            ReferralDetector,
            create_referral_detector,
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–ª–∞—Å—Å—ã –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª–∏—Å—å
        assert ScamDetector is not None
        assert callable(get_scam_detector)
        assert FloodDetector is not None
        assert callable(create_flood_detector)
        assert ReferralDetector is not None
        assert callable(create_referral_detector)


# ============================================================
# –¢–ï–°–¢–´ –î–õ–Ø ScamDetector (PHASE 2)
# ============================================================

class TestScamDetectorBasic:
    """–¢–µ—Å—Ç—ã –±–∞–∑–æ–≤–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ ScamDetector."""

    # –¢–µ—Å—Ç: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç
    def test_scam_empty_text(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("")
        assert result.is_scam is False
        assert result.score == 0

    # –¢–µ—Å—Ç: –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Å–∫–∞–º–∞
    def test_scam_normal_text(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?")
        assert result.is_scam is False
        assert result.score == 0

    # –¢–µ—Å—Ç: —Ç–µ–∫—Å—Ç —Å –¥–µ–Ω—å–≥–∞–º–∏ (1 —Å–∏–≥–Ω–∞–ª)
    def test_scam_money_only(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("–ü—Ä–æ–¥–∞–º —Ç–µ–ª–µ—Ñ–æ–Ω –∑–∞ 5000 —Ä—É–±–ª–µ–π")
        # –û–¥–∏–Ω —Å–∏–≥–Ω–∞–ª money_amount = 25 –±–∞–ª–ª–æ–≤
        # –ù–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è –ø—Ä–∏ sensitivity=60
        assert result.is_scam is False
        assert result.score == 25

    # –¢–µ—Å—Ç: —Ç–∏–ø–∏—á–Ω—ã–π —Å–∫–∞–º (–º–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤)
    def test_scam_typical_message(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check(
            "–ó–∞—Ä–∞–±–æ—Ç–∞–π 1200$ –∑–∞ –Ω–µ–¥–µ–ª—é! –ë–µ–∑ –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã. "
            "–ü–∏—à–∏ –º–Ω–µ @spam_bot –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å!"
        )
        # –ú–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–æ–≤: money_amount, income_period, call_to_action, urgency
        assert result.is_scam is True
        assert result.score >= 60

    # –¢–µ—Å—Ç: –∫—Ä–∏–ø—Ç–æ —Å–ø–∞–º
    def test_scam_crypto(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check(
            "Binance –¥–∞—ë—Ç 500 USDT –±–µ—Å–ø–ª–∞—Ç–Ω–æ! –ò–Ω–≤–µ—Å—Ç–∏—Ä—É–π –∏ –ø–æ–ª—É—á–∏ 1000$ –∑–∞ –¥–µ–Ω—å!"
        )
        # –°–∏–≥–Ω–∞–ª—ã: crypto, money_amount, income_period, urgency
        assert result.is_scam is True

    # –¢–µ—Å—Ç: —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è (–ø–æ—Ä–æ–≥ 40)
    def test_scam_high_sensitivity(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        # –î–æ–±–∞–≤–∏–º –±–æ–ª—å—à–µ —Å–∏–≥–Ω–∞–ª–æ–≤ —á—Ç–æ–±—ã –Ω–∞–±—Ä–∞—Ç—å >= 40 –±–∞–ª–ª–æ–≤
        result = detector.check("–ó–∞—Ä–∞–±–æ—Ç–∞–π 500$ –∑–∞ –Ω–µ–¥–µ–ª—é –ª–µ–≥–∫–æ! –ü–∏—à–∏ @bot", sensitivity=40)
        # money_amount (25) + income_period (20) + call_to_action (30) = 75 >= 40
        assert result.is_scam is True

    # –¢–µ—Å—Ç: —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è (–ø–æ—Ä–æ–≥ 90)
    def test_scam_low_sensitivity(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("–ó–∞—Ä–∞–±–æ—Ç–∞–π 500$ –ª–µ–≥–∫–æ!", sensitivity=90)
        # –ü—Ä–∏ –ø–æ—Ä–æ–≥–µ 90 –Ω—É–∂–Ω–æ –±–æ–ª—å—à–µ —Å–∏–≥–Ω–∞–ª–æ–≤
        assert result.is_scam is False


class TestScamDetectorSignals:
    """–¢–µ—Å—Ç—ã –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ ScamDetector."""

    # –¢–µ—Å—Ç: —Å–∏–≥–Ω–∞–ª call_to_action
    def test_signal_call_to_action(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("–ü–∏—à–∏ –º–Ω–µ @username –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å")
        # –°–∏–≥–Ω–∞–ª—ã –≤–∫–ª—é—á–∞—é—Ç –±–∞–ª–ª—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä 'call_to_action (+30)'
        assert any('call_to_action' in s for s in result.triggered_signals)

    # –¢–µ—Å—Ç: —Å–∏–≥–Ω–∞–ª guarantee
    def test_signal_guarantee(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("100% –≥–∞—Ä–∞–Ω—Ç–∏—è –∑–∞—Ä–∞–±–æ—Ç–∫–∞, —Ç–æ—á–Ω–æ!")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å–∏–≥–Ω–∞–ª guarantee –µ—Å—Ç—å
        assert any('guarantee' in s for s in result.triggered_signals)

    # –¢–µ—Å—Ç: —Å–∏–≥–Ω–∞–ª urgency
    def test_signal_urgency(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("–¢–æ–ª—å–∫–æ —Å–µ–≥–æ–¥–Ω—è! –£—Å–ø–µ–π!")
        # –°–∏–≥–Ω–∞–ª—ã –≤–∫–ª—é—á–∞—é—Ç –±–∞–ª–ª—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä 'urgency (+15)'
        assert any('urgency' in s for s in result.triggered_signals)

    # –¢–µ—Å—Ç: —Å–∏–≥–Ω–∞–ª crypto
    def test_signal_crypto(self):
        from bot.services.content_filter.scam_detector import ScamDetector
        detector = ScamDetector()
        result = detector.check("Binance –∏ Bybit —Ä–∞–∑–¥–∞—é—Ç –±–æ–Ω—É—Å—ã")
        # –°–∏–≥–Ω–∞–ª—ã –≤–∫–ª—é—á–∞—é—Ç –±–∞–ª–ª—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä 'crypto (+15)'
        assert any('crypto' in s for s in result.triggered_signals)


class TestScamDetectorSingleton:
    """–¢–µ—Å—Ç—ã —Å–∏–Ω–≥–ª—Ç–æ–Ω–∞ get_scam_detector."""

    def test_singleton_returns_same_instance(self):
        from bot.services.content_filter.scam_detector import get_scam_detector
        detector1 = get_scam_detector()
        detector2 = get_scam_detector()
        assert detector1 is detector2


# ============================================================
# –¢–ï–°–¢–´ –î–õ–Ø FloodDetector (PHASE 2)
# ============================================================

class TestFloodDetectorHash:
    """–¢–µ—Å—Ç—ã —Ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –≤ FloodDetector."""

    def test_compute_hash_same_text(self):
        """–û–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ç–µ–∫—Å—Ç –¥–∞—ë—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Ö—ç—à."""
        from bot.services.content_filter.flood_detector import FloodDetector
        from unittest.mock import MagicMock
        detector = FloodDetector(redis=MagicMock())
        hash1 = detector._compute_hash("—Ç–µ—Å—Ç")
        hash2 = detector._compute_hash("—Ç–µ—Å—Ç")
        assert hash1 == hash2

    def test_compute_hash_different_text(self):
        """–†–∞–∑–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∞—ë—Ç —Ä–∞–∑–Ω—ã–π —Ö—ç—à."""
        from bot.services.content_filter.flood_detector import FloodDetector
        from unittest.mock import MagicMock
        detector = FloodDetector(redis=MagicMock())
        hash1 = detector._compute_hash("—Ç–µ—Å—Ç1")
        hash2 = detector._compute_hash("—Ç–µ—Å—Ç2")
        assert hash1 != hash2

    def test_compute_hash_case_insensitive(self):
        """–•—ç—à –Ω–µ—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —Ä–µ–≥–∏—Å—Ç—Ä—É."""
        from bot.services.content_filter.flood_detector import FloodDetector
        from unittest.mock import MagicMock
        detector = FloodDetector(redis=MagicMock())
        hash1 = detector._compute_hash("–¢–ï–°–¢")
        hash2 = detector._compute_hash("—Ç–µ—Å—Ç")
        assert hash1 == hash2

    def test_compute_hash_ignores_whitespace(self):
        """–•—ç—à –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–±–µ–ª—ã –ø–æ –∫—Ä–∞—è–º."""
        from bot.services.content_filter.flood_detector import FloodDetector
        from unittest.mock import MagicMock
        detector = FloodDetector(redis=MagicMock())
        hash1 = detector._compute_hash("  —Ç–µ—Å—Ç  ")
        hash2 = detector._compute_hash("—Ç–µ—Å—Ç")
        assert hash1 == hash2


@pytest.mark.asyncio
async def test_flood_detector_empty_text():
    """–¢–µ—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—É—Å—Ç–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."""
    from bot.services.content_filter.flood_detector import FloodDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    detector = FloodDetector(redis=redis_mock)
    result = await detector.check("", chat_id=-100123, user_id=111)
    assert result.is_flood is False
    assert result.repeat_count == 0


@pytest.mark.asyncio
async def test_flood_detector_first_message():
    """–ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –¥–æ–ª–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å—Å—è —Ñ–ª—É–¥–æ–º."""
    from bot.services.content_filter.flood_detector import FloodDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    redis_mock.incr.return_value = 1  # –ü–µ—Ä–≤—ã–π —Ä–∞–∑
    detector = FloodDetector(redis=redis_mock)
    result = await detector.check("—Ç–µ—Å—Ç", chat_id=-100123, user_id=111)
    assert result.is_flood is False
    assert result.repeat_count == 1


@pytest.mark.asyncio
async def test_flood_detector_second_message():
    """–í—Ç–æ—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏ max_repeats=2 –Ω–µ —Ñ–ª—É–¥."""
    from bot.services.content_filter.flood_detector import FloodDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    redis_mock.incr.return_value = 2
    detector = FloodDetector(redis=redis_mock)
    result = await detector.check("—Ç–µ—Å—Ç", chat_id=-100123, user_id=111, max_repeats=2)
    assert result.is_flood is False
    assert result.repeat_count == 2


@pytest.mark.asyncio
async def test_flood_detector_third_message_is_flood():
    """–¢—Ä–µ—Ç—å–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏ max_repeats=2 = —Ñ–ª—É–¥."""
    from bot.services.content_filter.flood_detector import FloodDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    redis_mock.incr.return_value = 3  # –¢—Ä–µ—Ç–∏–π —Ä–∞–∑
    detector = FloodDetector(redis=redis_mock)
    result = await detector.check("—Ç–µ—Å—Ç", chat_id=-100123, user_id=111, max_repeats=2)
    assert result.is_flood is True
    assert result.repeat_count == 3


@pytest.mark.asyncio
async def test_flood_detector_redis_error():
    """–ü—Ä–∏ –æ—à–∏–±–∫–µ Redis –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    from bot.services.content_filter.flood_detector import FloodDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    redis_mock.incr.side_effect = Exception("Redis error")
    detector = FloodDetector(redis=redis_mock)
    result = await detector.check("—Ç–µ—Å—Ç", chat_id=-100123, user_id=111)
    assert result.is_flood is False


# ============================================================
# –¢–ï–°–¢–´ –î–õ–Ø ReferralDetector (PHASE 2)
# ============================================================

class TestReferralDetectorUsername:
    """–¢–µ—Å—Ç—ã –∏–∑–≤–ª–µ—á–µ–Ω–∏—è @username –≤ ReferralDetector."""

    def test_extract_single_username(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ @username."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        usernames = detector._extract_usernames("–ü–∏—à–∏ @testuser")
        assert "testuser" in usernames

    def test_extract_multiple_usernames(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö @username."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        usernames = detector._extract_usernames("@user1 –∏ @user2")
        assert len(usernames) == 2
        assert "user1" in usernames
        assert "user2" in usernames

    def test_extract_no_usernames(self):
        """–¢–µ–∫—Å—Ç –±–µ–∑ @username."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        usernames = detector._extract_usernames("–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç")
        assert len(usernames) == 0

    def test_extract_username_lowercase(self):
        """@username –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        usernames = detector._extract_usernames("–ü–∏—à–∏ @TestUser")
        assert "testuser" in usernames

    def test_extract_short_username_ignored(self):
        """–ö–æ—Ä–æ—Ç–∫–∏–µ @username (< 5 —Å–∏–º–≤–æ–ª–æ–≤) –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ username –≤ Telegram - 5 —Å–∏–º–≤–æ–ª–æ–≤
        usernames = detector._extract_usernames("@abc @abcd @abcde")
        # –¢–æ–ª—å–∫–æ @abcde (5 —Å–∏–º–≤–æ–ª–æ–≤) –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–≤–ª–µ—á—ë–Ω
        assert "abcde" in usernames
        assert "abc" not in usernames


class TestReferralDetectorCallToAction:
    """–¢–µ—Å—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑—ã–≤–∞ –∫ –¥–µ–π—Å—Ç–≤–∏—é."""

    def test_cta_detected(self):
        """–ü—Ä–∏–∑—ã–≤ –∫ –¥–µ–π—Å—Ç–≤–∏—é –æ–±–Ω–∞—Ä—É–∂–µ–Ω."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        has_cta = detector._has_call_to_action("–ø–∏—à–∏ –º–Ω–µ @user")
        assert has_cta is True

    def test_cta_subscribe(self):
        """–ü—Ä–∏–∑—ã–≤ –ø–æ–¥–ø–∏—Å–∞—Ç—å—Å—è."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        has_cta = detector._has_call_to_action("–ø–æ–¥–ø–∏—Å—ã–≤–∞–π—Å—è –Ω–∞ @channel")
        assert has_cta is True

    def test_no_cta(self):
        """–ù–µ—Ç –ø—Ä–∏–∑—ã–≤–∞ –∫ –¥–µ–π—Å—Ç–≤–∏—é."""
        from bot.services.content_filter.referral_detector import ReferralDetector
        from unittest.mock import MagicMock
        detector = ReferralDetector(redis=MagicMock())
        has_cta = detector._has_call_to_action("–º–æ–π –∫–∞–Ω–∞–ª @channel")
        assert has_cta is False


@pytest.mark.asyncio
async def test_referral_detector_empty_text():
    """–ü—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç –Ω–µ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–π —Å–ø–∞–º."""
    from bot.services.content_filter.referral_detector import ReferralDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    detector = ReferralDetector(redis=redis_mock)
    result = await detector.check("", chat_id=-100123, user_id=111)
    assert result.is_referral_spam is False


@pytest.mark.asyncio
async def test_referral_detector_no_username():
    """–¢–µ–∫—Å—Ç –±–µ–∑ @username –Ω–µ —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–π —Å–ø–∞–º."""
    from bot.services.content_filter.referral_detector import ReferralDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    detector = ReferralDetector(redis=redis_mock)
    result = await detector.check("–æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç", chat_id=-100123, user_id=111)
    assert result.is_referral_spam is False


@pytest.mark.asyncio
async def test_referral_detector_first_mention():
    """–ü–µ—Ä–≤–æ–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ @username –Ω–µ —Å–ø–∞–º."""
    from bot.services.content_filter.referral_detector import ReferralDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    redis_mock.incr.return_value = 1
    redis_mock.scard.return_value = 1
    detector = ReferralDetector(redis=redis_mock)
    result = await detector.check("–ø–∏—à–∏ @testuser", chat_id=-100123, user_id=111)
    assert result.is_referral_spam is False


@pytest.mark.asyncio
async def test_referral_detector_many_mentions():
    """–ú–Ω–æ–≥–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π = —Ä–µ—Ñ–µ—Ä–∞–ª—å–Ω—ã–π —Å–ø–∞–º."""
    from bot.services.content_filter.referral_detector import ReferralDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    redis_mock.incr.return_value = 6  # –ü—Ä–µ–≤—ã—à–µ–Ω –ø–æ—Ä–æ–≥ 5
    redis_mock.scard.return_value = 4
    detector = ReferralDetector(redis=redis_mock)
    result = await detector.check("–ø–∏—à–∏ @testuser", chat_id=-100123, user_id=111)
    assert result.is_referral_spam is True


@pytest.mark.asyncio
async def test_referral_detector_many_unique_users():
    """–ú–Ω–æ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π = —Å–ø–∞–º."""
    from bot.services.content_filter.referral_detector import ReferralDetector
    from unittest.mock import AsyncMock
    redis_mock = AsyncMock()
    redis_mock.incr.return_value = 3
    redis_mock.scard.return_value = 3  # –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ø–æ—Ä–æ–≥ unique_users_threshold
    detector = ReferralDetector(redis=redis_mock)
    result = await detector.check(
        "–ø–∏—à–∏ @testuser", chat_id=-100123, user_id=111,
        unique_users_threshold=3
    )
    assert result.is_referral_spam is True


# ============================================================
# –¢–ï–°–¢–´ –î–õ–Ø parse_duration (PHASE 3 - –ö–ê–¢–ï–ì–û–†–ò–ò)
# ============================================================

class TestParseDuration:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ parse_duration (–ø–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏)."""

    # –¢–µ—Å—Ç: —Å–µ–∫—É–Ω–¥—ã
    def test_parse_seconds(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        # 30 —Å–µ–∫—É–Ω–¥ = 0.5 –º–∏–Ω—É—Ç (–æ–∫—Ä—É–≥–ª—è–µ—Ç—Å—è –¥–æ 1)
        assert parse_duration("30s") == 1
        # 60 —Å–µ–∫—É–Ω–¥ = 1 –º–∏–Ω—É—Ç–∞
        assert parse_duration("60s") == 1
        # 120 —Å–µ–∫—É–Ω–¥ = 2 –º–∏–Ω—É—Ç—ã
        assert parse_duration("120s") == 2

    # –¢–µ—Å—Ç: –º–∏–Ω—É—Ç—ã
    def test_parse_minutes(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        assert parse_duration("5min") == 5
        assert parse_duration("30min") == 30
        assert parse_duration("60min") == 60

    # –¢–µ—Å—Ç: —á–∞—Å—ã
    def test_parse_hours(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        assert parse_duration("1h") == 60
        assert parse_duration("2h") == 120
        assert parse_duration("24h") == 1440

    # –¢–µ—Å—Ç: –¥–Ω–∏
    def test_parse_days(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        assert parse_duration("1d") == 1440  # 24 * 60
        assert parse_duration("7d") == 10080  # 7 * 24 * 60
        assert parse_duration("30d") == 43200  # 30 * 24 * 60

    # –¢–µ—Å—Ç: –º–µ—Å—è—Ü—ã
    def test_parse_months(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        assert parse_duration("1m") == 43200  # 30 * 24 * 60
        assert parse_duration("2m") == 86400  # 2 * 30 * 24 * 60

    # –¢–µ—Å—Ç: —Ç–æ–ª—å–∫–æ —á–∏—Å–ª–æ (–º–∏–Ω—É—Ç—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
    def test_parse_plain_number(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        assert parse_duration("60") == 60
        assert parse_duration("1440") == 1440

    # –¢–µ—Å—Ç: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤–≤–æ–¥
    def test_parse_invalid_input(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        assert parse_duration("abc") is None
        assert parse_duration("") is None
        assert parse_duration("   ") is None
        assert parse_duration("-10min") is None

    # –¢–µ—Å—Ç: –ø—Ä–æ–±–µ–ª—ã –≤–æ–∫—Ä—É–≥
    def test_parse_with_whitespace(self):
        from bot.handlers.content_filter.settings_handler import parse_duration
        assert parse_duration("  5min  ") == 5
        assert parse_duration(" 1h ") == 60


# ============================================================
# –¢–ï–°–¢–´ CALLBACK_DATA –î–õ–Ø –ö–ê–¢–ï–ì–û–†–ò–ô (PHASE 3)
# ============================================================

class TestCategoryCallbackDataLimit:
    """–¢–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —á—Ç–æ callback_data –∫–∞—Ç–µ–≥–æ—Ä–∏–π —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ 64 –±–∞–π—Ç–∞."""

    # –¢–µ—Å—Ç: callback –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Å–ª–æ–≤
    def test_word_filter_settings_callback(self):
        chat_id = -10023026384650
        callback = f"cf:wf_set:{chat_id}"
        assert len(callback.encode('utf-8')) <= 64

    # –¢–µ—Å—Ç: callback toggle –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    def test_category_toggle_callback(self):
        chat_id = -10023026384650
        # sw = simple words, hw = harmful words, ow = obfuscated words
        for cat in ['sw', 'hw', 'ow']:
            callback = f"cf:toggle:{cat}:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64, f"Callback {callback} too long"

    # –¢–µ—Å—Ç: callback –º–µ–Ω—é –¥–µ–π—Å—Ç–≤–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    def test_category_action_menu_callback(self):
        chat_id = -10023026384650
        for cat in ['simple', 'harmful', 'obfuscated']:
            callback = f"cf:cat_act:{cat}:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64, f"Callback {callback} too long"

    # –¢–µ—Å—Ç: callback —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –¥–µ–π—Å—Ç–≤–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
    def test_set_category_action_callback(self):
        chat_id = -10023026384650
        actions = ['delete', 'warn', 'mute', 'kick', 'ban']
        for cat in ['simple', 'harmful', 'obfuscated']:
            for action in actions:
                callback = f"cf:cat_sa:{cat}:{action}:{chat_id}"
                assert len(callback.encode('utf-8')) <= 64, f"Callback {callback} too long"

    # –¢–µ—Å—Ç: callback –∑–∞–ø—Ä–æ—Å–∞ –≤–≤–æ–¥–∞ –≤—Ä–µ–º–µ–Ω–∏
    def test_duration_input_callback(self):
        chat_id = -10023026384650
        for cat in ['simple', 'harmful', 'obfuscated']:
            callback = f"cf:cat_dur:{cat}:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64, f"Callback {callback} too long"

    # –¢–µ—Å—Ç: callback –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º –Ω–∞—Å—Ç—Ä–æ–µ–∫
    def test_scam_settings_callback(self):
        chat_id = -10023026384650
        callback = f"cf:scam_set:{chat_id}"
        assert len(callback.encode('utf-8')) <= 64


# ============================================================
# –¢–ï–°–¢–´ –õ–û–ì–ò–ö–ò –ö–ê–¢–ï–ì–û–†–ò–ô (PHASE 3)
# ============================================================

@pytest.mark.asyncio
async def test_word_category_defaults_in_database(db_session):
    """–¢–µ—Å—Ç –¥–µ—Ñ–æ–ª—Ç–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–π –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –≤ –ë–î."""
    # –°–æ–∑–¥–∞—ë–º –≥—Ä—É–ø–ø—É
    chat_id = -1080808080808
    group = Group(chat_id=chat_id, title="Category Defaults Test")
    db_session.add(group)
    await db_session.commit()

    # –°–æ–∑–¥–∞—ë–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–æ–ª—å–∫–æ —Å chat_id
    settings = ContentFilterSettings(chat_id=chat_id)
    db_session.add(settings)
    await db_session.commit()

    # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ –ë–î —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –¥–µ—Ñ–æ–ª—Ç—ã
    await db_session.refresh(settings)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º simple_words –¥–µ—Ñ–æ–ª—Ç—ã
    assert settings.simple_words_enabled is True
    assert settings.simple_words_action == 'delete'
    assert settings.simple_words_mute_duration is None

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º harmful_words –¥–µ—Ñ–æ–ª—Ç—ã
    assert settings.harmful_words_enabled is True
    assert settings.harmful_words_action == 'ban'
    assert settings.harmful_words_mute_duration is None

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º obfuscated_words –¥–µ—Ñ–æ–ª—Ç—ã
    assert settings.obfuscated_words_enabled is True
    assert settings.obfuscated_words_action == 'mute'
    assert settings.obfuscated_words_mute_duration == 1440


@pytest.mark.asyncio
async def test_word_filter_with_simple_category(db_session):
    """–¢–µ—Å—Ç —Å–ª–æ–≤–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π simple."""
    chat_id = -1050505050505
    group = Group(chat_id=chat_id, title="Test Group")
    db_session.add(group)
    await db_session.commit()

    word_filter = WordFilter()
    await word_filter.add_word(
        chat_id=chat_id,
        word="—Ä–µ–∫–ª–∞–º–∞",
        created_by=123456,
        session=db_session,
        category="simple"
    )

    result = await word_filter.check("—ç—Ç–æ —Ä–µ–∫–ª–∞–º–∞ —Ç–æ–≤–∞—Ä–∞", chat_id, db_session)
    assert result.matched is True
    assert result.category == "simple"


@pytest.mark.asyncio
async def test_word_filter_with_harmful_category(db_session):
    """–¢–µ—Å—Ç —Å–ª–æ–≤–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π harmful."""
    chat_id = -1060606060606
    group = Group(chat_id=chat_id, title="Test Group")
    db_session.add(group)
    await db_session.commit()

    word_filter = WordFilter()
    await word_filter.add_word(
        chat_id=chat_id,
        word="–Ω–∞—Ä–∫–æ—Ç–∞",
        created_by=123456,
        session=db_session,
        category="harmful"
    )

    result = await word_filter.check("–ø—Ä–æ–¥–∞—é –Ω–∞—Ä–∫–æ—Ç–∞", chat_id, db_session)
    assert result.matched is True
    assert result.category == "harmful"


@pytest.mark.asyncio
async def test_word_filter_with_obfuscated_category(db_session):
    """–¢–µ—Å—Ç —Å–ª–æ–≤–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π obfuscated (l33tspeak)."""
    chat_id = -1070707070707
    group = Group(chat_id=chat_id, title="Test Group")
    db_session.add(group)
    await db_session.commit()

    word_filter = WordFilter()
    await word_filter.add_word(
        chat_id=chat_id,
        word="–∫–æ–∫–∞",
        created_by=123456,
        session=db_session,
        category="obfuscated"
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º l33tspeak –≤–µ—Ä—Å–∏—é
    result = await word_filter.check("–ø—Ä–æ–¥–∞—é k0k@", chat_id, db_session)
    assert result.matched is True
    assert result.category == "obfuscated"


# ============================================================
# –¢–ï–°–¢–´ –ö–õ–ê–í–ò–ê–¢–£–† –ê–ù–¢–ò–§–õ–£–î–ê (–ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø)
# ============================================================

class TestFloodActionMenuNoDefaultButton:
    """–¢–µ—Å—Ç—ã —á—Ç–æ –∫–Ω–æ–ø–∫–∞ '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–µ–µ' —É–¥–∞–ª–µ–Ω–∞ –∏–∑ –º–µ–Ω—é –∞–Ω—Ç–∏—Ñ–ª—É–¥–∞."""

    def test_flood_action_menu_no_default_button(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –∫–Ω–æ–ø–∫–∏ '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–µ–µ'."""
        from bot.keyboards.content_filter_keyboards import create_flood_action_menu

        chat_id = -1001234567890
        keyboard = create_flood_action_menu(chat_id, current_action=None)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫
        button_texts = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                button_texts.append(btn.text)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –∫–Ω–æ–ø–∫–∏ "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–µ–µ"
        assert not any("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–µ–µ" in text for text in button_texts), \
            "–ö–Ω–æ–ø–∫–∞ '–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ–±—â–µ–µ' –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–∞"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å –∫–Ω–æ–ø–∫–∞ "–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å"
        assert any("–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å" in text for text in button_texts), \
            "–ö–Ω–æ–ø–∫–∞ '–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å' –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å"

    def test_flood_action_menu_delete_default_checked(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ '–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å' –≤—ã–±—Ä–∞–Ω–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫–æ–≥–¥–∞ action=None."""
        from bot.keyboards.content_filter_keyboards import create_flood_action_menu

        chat_id = -1001234567890
        keyboard = create_flood_action_menu(chat_id, current_action=None)

        # –ò—â–µ–º –∫–Ω–æ–ø–∫—É "–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å" –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —É –Ω–µ—ë –µ—Å—Ç—å ‚úì
        for row in keyboard.inline_keyboard:
            for btn in row:
                if "–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å" in btn.text:
                    assert "‚úì" in btn.text, \
                        "'–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å' –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–±—Ä–∞–Ω–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é (action=None)"
                    return

        pytest.fail("–ö–Ω–æ–ø–∫–∞ '–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

    def test_flood_action_menu_mute_checked(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ '–ú—É—Ç' –≤—ã–±—Ä–∞–Ω –∫–æ–≥–¥–∞ action='mute'."""
        from bot.keyboards.content_filter_keyboards import create_flood_action_menu

        chat_id = -1001234567890
        keyboard = create_flood_action_menu(chat_id, current_action='mute')

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ "–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å" –ù–ï –≤—ã–±—Ä–∞–Ω–∞
        # –∏ —á—Ç–æ "–ú—É—Ç" –≤—ã–±—Ä–∞–Ω–∞
        for row in keyboard.inline_keyboard:
            for btn in row:
                if "–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å" in btn.text:
                    assert "‚úì" not in btn.text, \
                        "'–¢–æ–ª—å–∫–æ —É–¥–∞–ª–∏—Ç—å' –Ω–µ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–±—Ä–∞–Ω–∞ –∫–æ–≥–¥–∞ action='mute'"
                if "–ú—É—Ç" in btn.text and "–£–¥–∞–ª–∏—Ç—å + –ú—É—Ç" in btn.text:
                    assert "‚úì" in btn.text, \
                        "'–ú—É—Ç' –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤—ã–±—Ä–∞–Ω–∞ –∫–æ–≥–¥–∞ action='mute'"


class TestFloodSettingsMenuCustomInput:
    """–¢–µ—Å—Ç—ã –∫–Ω–æ–ø–æ–∫ —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö –∞–Ω—Ç–∏—Ñ–ª—É–¥–∞."""

    def test_flood_settings_has_custom_repeats_button(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–Ω–æ–ø–∫–∏ ‚úèÔ∏è –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ max_repeats."""
        from bot.keyboards.content_filter_keyboards import create_flood_settings_menu

        chat_id = -1001234567890
        keyboard = create_flood_settings_menu(chat_id, max_repeats=3, time_window=60)

        # –ò—â–µ–º –∫–Ω–æ–ø–∫—É —Å callback cf:flrc (flood repeats custom)
        callbacks = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                callbacks.append(btn.callback_data)

        assert any("cf:flrc:" in cb for cb in callbacks), \
            "–î–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ max_repeats (cf:flrc)"

    def test_flood_settings_has_custom_window_button(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–Ω–æ–ø–∫–∏ ‚úèÔ∏è –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ time_window."""
        from bot.keyboards.content_filter_keyboards import create_flood_settings_menu

        chat_id = -1001234567890
        keyboard = create_flood_settings_menu(chat_id, max_repeats=3, time_window=60)

        # –ò—â–µ–º –∫–Ω–æ–ø–∫—É —Å callback cf:flwc (flood window custom)
        callbacks = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                callbacks.append(btn.callback_data)

        assert any("cf:flwc:" in cb for cb in callbacks), \
            "–î–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ –¥–ª—è —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ time_window (cf:flwc)"

    def test_flood_settings_custom_repeats_shows_value(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ max_repeats –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Å ‚úì."""
        from bot.keyboards.content_filter_keyboards import create_flood_settings_menu

        chat_id = -1001234567890
        # 7 - –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ: 2, 3, 5)
        keyboard = create_flood_settings_menu(chat_id, max_repeats=7, time_window=60)

        # –ò—â–µ–º –∫–Ω–æ–ø–∫—É —Å ‚úèÔ∏è –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        for row in keyboard.inline_keyboard:
            for btn in row:
                if "cf:flrc:" in btn.callback_data:
                    assert "7" in btn.text, \
                        f"–ö–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 7, –Ω–æ text='{btn.text}'"
                    assert "‚úì" in btn.text, \
                        f"–ö–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å ‚úì –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–æ text='{btn.text}'"

    def test_flood_settings_custom_window_shows_value(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ time_window –æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Å ‚úì."""
        from bot.keyboards.content_filter_keyboards import create_flood_settings_menu

        chat_id = -1001234567890
        # 90 - –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ (—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ: 30, 60, 120)
        keyboard = create_flood_settings_menu(chat_id, max_repeats=3, time_window=90)

        # –ò—â–µ–º –∫–Ω–æ–ø–∫—É —Å ‚úèÔ∏è –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        for row in keyboard.inline_keyboard:
            for btn in row:
                if "cf:flwc:" in btn.callback_data:
                    assert "90" in btn.text, \
                        f"–ö–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ 90, –Ω–æ text='{btn.text}'"
                    assert "‚úì" in btn.text, \
                        f"–ö–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å ‚úì –¥–ª—è –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–æ text='{btn.text}'"

    def test_flood_settings_standard_value_no_custom_check(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ –∏–º–µ—é—Ç ‚úì –≤ –∫–Ω–æ–ø–∫–µ ‚úèÔ∏è."""
        from bot.keyboards.content_filter_keyboards import create_flood_settings_menu

        chat_id = -1001234567890
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        keyboard = create_flood_settings_menu(chat_id, max_repeats=3, time_window=60)

        for row in keyboard.inline_keyboard:
            for btn in row:
                if "cf:flrc:" in btn.callback_data:
                    # –ü—Ä–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º –∑–Ω–∞—á–µ–Ω–∏–∏ –∫–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ø—Ä–æ—Å—Ç–æ ‚úèÔ∏è
                    assert btn.text == "‚úèÔ∏è", \
                        f"–ü—Ä–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º max_repeats=3 –∫–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å '‚úèÔ∏è', –Ω–æ text='{btn.text}'"
                if "cf:flwc:" in btn.callback_data:
                    assert btn.text == "‚úèÔ∏è", \
                        f"–ü—Ä–∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º time_window=60 –∫–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å '‚úèÔ∏è', –Ω–æ text='{btn.text}'"


# ============================================================
# –¢–ï–°–¢–´ –°–¢–†–£–ö–¢–£–†–´ –ú–ï–ù–Æ –ê–ù–¢–ò–°–ö–ê–ú–ê (–ò–°–ü–†–ê–í–õ–ï–ù–ò–Ø)
# ============================================================

class TestScamSettingsMenuStructure:
    """–¢–µ—Å—Ç—ã —á—Ç–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –í–ù–£–¢–†–ò –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º–∞."""

    def test_scam_settings_has_sensitivity(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º–∞ –µ—Å—Ç—å –∫–Ω–æ–ø–∫–∞ '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'."""
        from bot.keyboards.content_filter_keyboards import create_scam_settings_menu
        from bot.database.models_content_filter import ContentFilterSettings

        chat_id = -1001234567890
        settings = ContentFilterSettings(
            chat_id=chat_id,
            scam_sensitivity=60,
            default_action='delete'
        )

        keyboard = create_scam_settings_menu(chat_id, settings)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫
        button_texts = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                button_texts.append(btn.text)

        assert any("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å" in text for text in button_texts), \
            "–í –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'"

    def test_scam_settings_has_action(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º–∞ –µ—Å—Ç—å –∫–Ω–æ–ø–∫–∞ '–î–µ–π—Å—Ç–≤–∏–µ'."""
        from bot.keyboards.content_filter_keyboards import create_scam_settings_menu
        from bot.database.models_content_filter import ContentFilterSettings

        chat_id = -1001234567890
        settings = ContentFilterSettings(
            chat_id=chat_id,
            scam_sensitivity=60,
            default_action='delete'
        )

        keyboard = create_scam_settings_menu(chat_id, settings)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫
        button_texts = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                button_texts.append(btn.text)

        assert any("–î–µ–π—Å—Ç–≤–∏–µ" in text for text in button_texts), \
            "–í –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ '–î–µ–π—Å—Ç–≤–∏–µ'"

    def test_scam_settings_has_patterns(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º–∞ –µ—Å—Ç—å –∫–Ω–æ–ø–∫–∞ '–ü–∞—Ç—Ç–µ—Ä–Ω—ã'."""
        from bot.keyboards.content_filter_keyboards import create_scam_settings_menu
        from bot.database.models_content_filter import ContentFilterSettings

        chat_id = -1001234567890
        settings = ContentFilterSettings(
            chat_id=chat_id,
            scam_sensitivity=60,
            default_action='delete'
        )

        keyboard = create_scam_settings_menu(chat_id, settings)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫
        button_texts = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                button_texts.append(btn.text)

        assert any("–ü–∞—Ç—Ç–µ—Ä–Ω—ã" in text for text in button_texts), \
            "–í –º–µ–Ω—é –∞–Ω—Ç–∏—Å–∫–∞–º–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ '–ü–∞—Ç—Ç–µ—Ä–Ω—ã'"


class TestGeneralSettingsMenuNoScamOptions:
    """–¢–µ—Å—Ç—ã —á—Ç–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ –¥–µ–π—Å—Ç–≤–∏–µ —É–±—Ä–∞–Ω—ã –∏–∑ –æ–±—â–µ–≥–æ –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫."""

    def test_general_settings_no_sensitivity(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –æ–±—â–µ–º –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ù–ï–¢ –∫–Ω–æ–ø–∫–∏ '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å'."""
        from bot.keyboards.content_filter_keyboards import create_content_filter_settings_menu
        from bot.database.models_content_filter import ContentFilterSettings

        chat_id = -1001234567890
        settings = ContentFilterSettings(
            chat_id=chat_id,
            scam_sensitivity=60,
            default_action='delete'
        )

        keyboard = create_content_filter_settings_menu(chat_id, settings)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫
        button_texts = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                button_texts.append(btn.text)

        assert not any("–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å" in text for text in button_texts), \
            "–í –æ–±—â–µ–º –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ù–ï –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∏ '–ß—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å' (—Ç–æ–ª—å–∫–æ –≤ –∞–Ω—Ç–∏—Å–∫–∞–º–µ)"

    def test_general_settings_no_default_action(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –æ–±—â–µ–º –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ù–ï–¢ –∫–Ω–æ–ø–∫–∏ '–î–µ–π—Å—Ç–≤–∏–µ:'."""
        from bot.keyboards.content_filter_keyboards import create_content_filter_settings_menu
        from bot.database.models_content_filter import ContentFilterSettings

        chat_id = -1001234567890
        settings = ContentFilterSettings(
            chat_id=chat_id,
            scam_sensitivity=60,
            default_action='delete'
        )

        keyboard = create_content_filter_settings_menu(chat_id, settings)

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫
        button_texts = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                button_texts.append(btn.text)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–µ—Ç –∫–Ω–æ–ø–∫–∏ "–î–µ–π—Å—Ç–≤–∏–µ:" (–æ–±—â–µ–µ –¥–µ–π—Å—Ç–≤–∏–µ)
        # –ù–æ –º–æ–≥—É—Ç –±—ã—Ç—å ‚ö° –∫–Ω–æ–ø–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥—É–ª–µ–π
        assert not any(text.startswith("–î–µ–π—Å—Ç–≤–∏–µ:") for text in button_texts), \
            "–í –æ–±—â–µ–º –º–µ–Ω—é –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ù–ï –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∏ '–î–µ–π—Å—Ç–≤–∏–µ:' (—Ç–æ–ª—å–∫–æ –≤ –∞–Ω—Ç–∏—Å–∫–∞–º–µ)"

    def test_general_settings_has_scam_settings_button(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –æ–±—â–µ–º –º–µ–Ω—é –µ—Å—Ç—å –∫–Ω–æ–ø–∫–∞ ‚öôÔ∏è –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω—Ç–∏—Å–∫–∞–º–∞."""
        from bot.keyboards.content_filter_keyboards import create_content_filter_settings_menu
        from bot.database.models_content_filter import ContentFilterSettings

        chat_id = -1001234567890
        settings = ContentFilterSettings(
            chat_id=chat_id,
            scam_sensitivity=60,
            default_action='delete'
        )

        keyboard = create_content_filter_settings_menu(chat_id, settings)

        # –ò—â–µ–º callback cf:scs (scam settings)
        callbacks = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                callbacks.append(btn.callback_data)

        assert any("cf:scs:" in cb for cb in callbacks), \
            "–î–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω—Ç–∏—Å–∫–∞–º–∞ (cf:scs)"


# ============================================================
# –¢–ï–°–¢–´ –í–ê–õ–ò–î–ê–¶–ò–ò –†–£–ß–ù–û–ì–û –í–í–û–î–ê –ê–ù–¢–ò–§–õ–£–î–ê
# ============================================================

class TestFloodCustomInputValidation:
    """–¢–µ—Å—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞–Ω—Ç–∏—Ñ–ª—É–¥–∞."""

    def test_max_repeats_valid_range(self):
        """–¢–µ—Å—Ç —á—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω max_repeats: 1-50."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        valid_values = [1, 2, 10, 25, 49, 50]
        invalid_values = [0, -1, 51, 100, -10]

        for val in valid_values:
            assert 1 <= val <= 50, f"{val} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 1-50"

        for val in invalid_values:
            assert not (1 <= val <= 50), f"{val} –ù–ï –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 1-50"

    def test_time_window_valid_range(self):
        """–¢–µ—Å—Ç —á—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω time_window: 10-600."""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≥—Ä–∞–Ω–∏—á–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        valid_values = [10, 30, 60, 120, 300, 599, 600]
        invalid_values = [0, 5, 9, 601, 1000, -10]

        for val in valid_values:
            assert 10 <= val <= 600, f"{val} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 10-600"

        for val in invalid_values:
            assert not (10 <= val <= 600), f"{val} –ù–ï –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ 10-600"


# ============================================================
# –¢–ï–°–¢–´ CALLBACK –ê–ù–¢–ò–§–õ–£–î–ê (–õ–ò–ú–ò–¢ 64 –ë–ê–ô–¢–ê)
# ============================================================

class TestFloodCallbackDataLimit:
    """–¢–µ—Å—Ç—ã —á—Ç–æ callback_data –∞–Ω—Ç–∏—Ñ–ª—É–¥–∞ —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç 64 –±–∞–π—Ç–∞."""

    def test_flood_custom_repeats_callback(self):
        """Callback —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –ø–æ–≤—Ç–æ—Ä–æ–≤ —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç."""
        chat_id = -10023026384650  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–ª–∏–Ω–Ω—ã–π chat_id
        callback = f"cf:flrc:{chat_id}"
        assert len(callback.encode('utf-8')) <= 64, f"Callback '{callback}' –ø—Ä–µ–≤—ã—à–∞–µ—Ç 64 –±–∞–π—Ç–∞"

    def test_flood_custom_window_callback(self):
        """Callback —Ä—É—á–Ω–æ–≥–æ –≤–≤–æ–¥–∞ –æ–∫–Ω–∞ —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç."""
        chat_id = -10023026384650
        callback = f"cf:flwc:{chat_id}"
        assert len(callback.encode('utf-8')) <= 64, f"Callback '{callback}' –ø—Ä–µ–≤—ã—à–∞–µ—Ç 64 –±–∞–π—Ç–∞"

    def test_flood_action_callback(self):
        """Callback –≤—ã–±–æ—Ä–∞ –¥–µ–π—Å—Ç–≤–∏—è —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç."""
        chat_id = -10023026384650
        actions = ['delete', 'warn', 'mute', 'ban']
        for action in actions:
            callback = f"cf:fact:{action}:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64, f"Callback '{callback}' –ø—Ä–µ–≤—ã—à–∞–µ—Ç 64 –±–∞–π—Ç–∞"

    def test_scam_settings_callback(self):
        """Callback –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∞–Ω—Ç–∏—Å–∫–∞–º–∞ —É–∫–ª–∞–¥—ã–≤–∞–µ—Ç—Å—è –≤ –ª–∏–º–∏—Ç."""
        chat_id = -10023026384650
        callback = f"cf:scs:{chat_id}"
        assert len(callback.encode('utf-8')) <= 64, f"Callback '{callback}' –ø—Ä–µ–≤—ã—à–∞–µ—Ç 64 –±–∞–π—Ç–∞"


# ============================================================
# –¢–ï–°–¢–´ –ò–°–ü–†–ê–í–õ–ï–ù–ò–ô –ë–ê–ì–û–í (fix_bugs.md)
# ============================================================
# –≠—Ç–∏ —Ç–µ—Å—Ç—ã –ø—Ä–æ–≤–µ—Ä—è—é—Ç —á—Ç–æ –±–∞–≥–∏ –∏–∑ docs/fix_bugs/fix_bugs.md –∏—Å–ø—Ä–∞–≤–ª–µ–Ω—ã:
# 1. NameError: InlineKeyboardMarkup –Ω–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω
# 2. –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–∞–ª—Å—è –∫–Ω–æ–ø–∫–∞–º–∏ –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞
# 3. –ö–Ω–æ–ø–∫–∞ "–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ" —Ä–∞–±–æ—Ç–∞–µ—Ç —á–µ—Ä–µ–∑ FSM
# ============================================================

class TestBugFixNameErrorImports:
    """
    –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–∞: NameError - InlineKeyboardMarkup –Ω–µ –±—ã–ª –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω.

    –ë–∞–≥: –í settings_handler.py –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏—Å—å InlineKeyboardMarkup –∏
    InlineKeyboardButton, –Ω–æ –æ–Ω–∏ –Ω–µ –±—ã–ª–∏ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã.

    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç –≤ —Å—Ç—Ä–æ–∫–µ 16:
    from aiogram.types import CallbackQuery, Message, InlineKeyboardMarkup, InlineKeyboardButton
    """

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ InlineKeyboardMarkup –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –∏–∑ settings_handler
    def test_inline_keyboard_markup_importable(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ InlineKeyboardMarkup –¥–æ—Å—Ç—É–ø–µ–Ω –≤ settings_handler."""
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å settings_handler
        from bot.handlers.content_filter import settings_handler
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ InlineKeyboardMarkup –≤ –æ–±–ª–∞—Å—Ç–∏ –≤–∏–¥–∏–º–æ—Å—Ç–∏ –º–æ–¥—É–ª—è
        # (–ª–∏–±–æ —á–µ—Ä–µ–∑ –∏–º–ø–æ—Ä—Ç, –ª–∏–±–æ —á–µ—Ä–µ–∑ aiogram.types)
        from aiogram.types import InlineKeyboardMarkup as IKM
        # –ï—Å–ª–∏ –º–æ–¥—É–ª—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫ - –∏–º–ø–æ—Ä—Ç –µ—Å—Ç—å
        assert settings_handler is not None

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ InlineKeyboardButton –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –∏–∑ settings_handler
    def test_inline_keyboard_button_importable(self):
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ InlineKeyboardButton –¥–æ—Å—Ç—É–ø–µ–Ω –≤ settings_handler."""
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥—É–ª—å settings_handler
        from bot.handlers.content_filter import settings_handler
        # –ï—Å–ª–∏ –º–æ–¥—É–ª—å –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–ª—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫ - –∏–º–ø–æ—Ä—Ç –µ—Å—Ç—å
        from aiogram.types import InlineKeyboardButton as IKB
        assert settings_handler is not None

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥—É–ª—å settings_handler –Ω–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç NameError –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
    def test_settings_handler_imports_without_name_error(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ settings_handler –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è –±–µ–∑ NameError.

        –≠—Ç–æ—Ç —Ç–µ—Å—Ç –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç –±–∞–≥: —Ä–∞–Ω–µ–µ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –≤—ã–±—Ä–∞—Å—ã–≤–∞–ª—Å—è
        NameError: name 'InlineKeyboardMarkup' is not defined
        """
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥—É–ª—å
            from bot.handlers.content_filter import settings_handler
            # –ï—Å–ª–∏ –∏–º–ø–æ—Ä—Ç —É—Å–ø–µ—à–µ–Ω - –±–∞–≥ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω
            import_success = True
        except NameError as e:
            # –ï—Å–ª–∏ NameError - –±–∞–≥ –Ω–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω
            import_success = False
            pytest.fail(f"NameError –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ settings_handler: {e}")

        assert import_success is True


class TestBugFixWordsListDisplay:
    """
    –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–∞: —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤ –æ—Ç–æ–±—Ä–∞–∂–∞–ª—Å—è –∫–Ω–æ–ø–∫–∞–º–∏ –≤–º–µ—Å—Ç–æ —Ç–µ–∫—Å—Ç–∞.

    –ë–∞–≥: –°–ª–æ–≤–∞ –æ—Ç–æ–±—Ä–∞–∂–∞–ª–∏—Å—å –∫–∞–∫ –∫–Ω–æ–ø–∫–∏ —Å ‚ùå, –∞ –Ω–µ –∫–∞–∫ —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å–ø–∏—Å–æ–∫.

    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –§—É–Ω–∫—Ü–∏—è create_category_words_list_menu —Ç–µ–ø–µ—Ä—å –ù–ï –ø—Ä–∏–Ω–∏–º–∞–µ—Ç
    –ø–∞—Ä–∞–º–µ—Ç—Ä—ã word_ids –∏ words - —Å–ª–æ–≤–∞ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è.
    """

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É —Ñ—É–Ω–∫—Ü–∏–∏ create_category_words_list_menu
    def test_category_words_list_menu_signature(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ create_category_words_list_menu –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ç–æ–ª—å–∫–æ 4 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞.

        –ü–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞—Ç—å:
        - chat_id: int
        - category: str
        - page: int
        - total_pages: int

        –ò –ù–ï –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞—Ç—å word_ids –∏ words (–æ–Ω–∏ —É–±—Ä–∞–Ω—ã).
        """
        import inspect
        from bot.keyboards.content_filter_keyboards import create_category_words_list_menu

        # –ü–æ–ª—É—á–∞–µ–º —Å–∏–≥–Ω–∞—Ç—É—Ä—É —Ñ—É–Ω–∫—Ü–∏–∏
        sig = inspect.signature(create_category_words_list_menu)
        params = list(sig.parameters.keys())

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ç–æ–ª—å–∫–æ 4 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        assert len(params) == 4, \
            f"–û–∂–∏–¥–∞–ª–æ—Å—å 4 –ø–∞—Ä–∞–º–µ—Ç—Ä–∞, –ø–æ–ª—É—á–µ–Ω–æ {len(params)}: {params}"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–º–µ–Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        assert 'chat_id' in params, "–ü–∞—Ä–∞–º–µ—Ç—Ä chat_id –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å"
        assert 'category' in params, "–ü–∞—Ä–∞–º–µ—Ç—Ä category –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å"
        assert 'page' in params, "–ü–∞—Ä–∞–º–µ—Ç—Ä page –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å"
        assert 'total_pages' in params, "–ü–∞—Ä–∞–º–µ—Ç—Ä total_pages –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å"

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ word_ids –∏ words –£–î–ê–õ–ï–ù–´
        assert 'word_ids' not in params, \
            "–ü–∞—Ä–∞–º–µ—Ç—Ä word_ids –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–¥–∞–ª—ë–Ω (—Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ, –Ω–µ –∫–Ω–æ–ø–∫–∞—Ö)"
        assert 'words' not in params, \
            "–ü–∞—Ä–∞–º–µ—Ç—Ä words –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —É–¥–∞–ª—ë–Ω (—Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ, –Ω–µ –∫–Ω–æ–ø–∫–∞—Ö)"

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ word_ids –∏ words
    def test_category_words_list_menu_works_without_words_params(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ create_category_words_list_menu —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ word_ids –∏ words.
        """
        from bot.keyboards.content_filter_keyboards import create_category_words_list_menu

        chat_id = -1001234567890
        # –í—ã–∑—ã–≤–∞–µ–º –±–µ–∑ word_ids –∏ words - –¥–æ–ª–∂–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å
        keyboard = create_category_words_list_menu(
            chat_id=chat_id,
            category='sw',
            page=0,
            total_pages=1
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤–µ—Ä–Ω—É–ª–∞—Å—å –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞
        from aiogram.types import InlineKeyboardMarkup
        assert isinstance(keyboard, InlineKeyboardMarkup)

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–Ω–æ–ø–æ–∫ —Å ‚ùå —Å–ª–æ–≤–æ
    def test_category_words_list_menu_no_word_delete_buttons(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –ù–ï —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–Ω–æ–ø–æ–∫ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤ (‚ùå —Å–ª–æ–≤–æ).

        –ü–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –≤ —Ç–µ–∫—Å—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏—è,
        –∞ –Ω–µ –∫–∞–∫ –∫–Ω–æ–ø–∫–∏ —Å ‚ùå.
        """
        from bot.keyboards.content_filter_keyboards import create_category_words_list_menu

        chat_id = -1001234567890
        keyboard = create_category_words_list_menu(
            chat_id=chat_id,
            category='sw',
            page=0,
            total_pages=1
        )

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –ù–ï–¢ –∫–Ω–æ–ø–æ–∫ —Å callback —Ç–∏–ø–∞ cf:cwd (category word delete)
        # –∫–æ—Ç–æ—Ä—ã–µ —É–¥–∞–ª—è—é—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ —Å–ª–æ–≤–æ
        for row in keyboard.inline_keyboard:
            for btn in row:
                # –ö–Ω–æ–ø–∫–∏ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤ –∏–º–µ–ª–∏ –±—ã callback –≤–∏–¥–∞ cf:cwd:word_id:...
                assert not (btn.callback_data and btn.callback_data.startswith("cf:cwd:")), \
                    f"–ù–∞–π–¥–µ–Ω–∞ –∫–Ω–æ–ø–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞: {btn.text} -> {btn.callback_data}"


class TestBugFixDeleteWordFSM:
    """
    –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–∞: –∫–Ω–æ–ø–∫–∞ "–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ" –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å —á–µ—Ä–µ–∑ FSM.

    –ë–∞–≥: –ö–Ω–æ–ø–∫–∞ "–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ" –Ω–µ —Ä–∞–±–æ—Ç–∞–ª–∞.

    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: FSM —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–æ,
    –ø—Ä–æ–±–ª–µ–º–∞ –±—ã–ª–∞ –≤ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ –∏ callback_data.
    """

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ FSM —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    def test_delete_word_fsm_state_exists(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ settings_handler –µ—Å—Ç—å FSM —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤.
        """
        from bot.handlers.content_filter import settings_handler

        # –ò—â–µ–º –∫–ª–∞—Å—Å —Å–æ—Å—Ç–æ—è–Ω–∏–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        # –ú–æ–∂–µ—Ç –Ω–∞–∑—ã–≤–∞—Ç—å—Å—è DeleteWordStates –∏–ª–∏ –ø–æ–¥–æ–±–Ω–æ
        has_delete_states = False

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –º–æ–¥—É–ª—è
        for attr_name in dir(settings_handler):
            attr = getattr(settings_handler, attr_name, None)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –∫–ª–∞—Å—Å StatesGroup
            if attr and hasattr(attr, '__mro__'):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç StatesGroup
                from aiogram.fsm.state import StatesGroup
                if StatesGroup in getattr(attr, '__mro__', []):
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
                    if 'delete' in attr_name.lower() or 'word' in attr_name.lower():
                        has_delete_states = True
                        break

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –∏—â–µ–º —Ö–µ–Ω–¥–ª–µ—Ä —Å FSM –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ router —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        assert hasattr(settings_handler, 'settings_handler_router'), \
            "Router settings_handler_router –¥–æ–ª–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å"

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –∫–Ω–æ–ø–∫–∞ "–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ" –µ—Å—Ç—å –≤ –∫–ª–∞–≤–∏–∞—Ç—É—Ä–µ
    def test_delete_word_button_exists_in_menu(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ –º–µ–Ω—é —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤ –µ—Å—Ç—å –∫–Ω–æ–ø–∫–∞ "–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ".
        """
        from bot.keyboards.content_filter_keyboards import create_category_words_list_menu

        chat_id = -1001234567890
        keyboard = create_category_words_list_menu(
            chat_id=chat_id,
            category='sw',
            page=0,
            total_pages=1
        )

        # –ò—â–µ–º –∫–Ω–æ–ø–∫—É —Å —Ç–µ–∫—Å—Ç–æ–º "–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ"
        button_texts = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                button_texts.append(btn.text)

        # –î–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∫–Ω–æ–ø–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è
        has_delete_button = any('–£–¥–∞–ª–∏—Ç—å' in text for text in button_texts)
        assert has_delete_button, \
            f"–ö–Ω–æ–ø–∫–∞ '–£–¥–∞–ª–∏—Ç—å —Å–ª–æ–≤–æ' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ö–Ω–æ–ø–∫–∏: {button_texts}"


class TestBugFixAddWordNotification:
    """
    –¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–≥–∞: –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–æ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–ª–æ–≤.

    –ë–∞–≥: –ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ —Å–ª–æ–≤ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–ª–æ—Å—å —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ.

    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: –£–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ —É–∂–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª–æ –≤ –∫–æ–¥–µ (‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ —Å–ª–æ–≤: N).
    """

    # –¢–µ—Å—Ç: –ø—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ settings_handler –µ—Å—Ç—å —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤
    def test_add_word_handler_exists(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –≤ settings_handler –µ—Å—Ç—å —Ö–µ–Ω–¥–ª–µ—Ä –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤.
        """
        from bot.handlers.content_filter import settings_handler

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –º–æ–¥—É–ª—å –∏–º–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç—Å—è —É—Å–ø–µ—à–Ω–æ
        assert settings_handler is not None

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ FSM —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        assert hasattr(settings_handler, 'AddWordStates'), \
            "–ö–ª–∞—Å—Å AddWordStates –¥–æ–ª–∂–µ–Ω —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –¥–ª—è FSM –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤"


# ============================================================
# –¢–ï–°–¢–´ CALLBACK –ö–ê–¢–ï–ì–û–†–ò–ô –°–õ–û–í
# ============================================================

class TestCategoryWordsListMenuCallbacks:
    """–¢–µ—Å—Ç—ã callback_data –¥–ª—è –º–µ–Ω—é —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤ –∫–∞—Ç–µ–≥–æ—Ä–∏–π."""

    # –¢–µ—Å—Ç: callback —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ FSM
    def test_delete_word_fsm_callback_exists(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å callback –¥–ª—è –∑–∞–ø—É—Å–∫–∞ FSM —É–¥–∞–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞.
        """
        from bot.keyboards.content_filter_keyboards import create_category_words_list_menu

        chat_id = -1001234567890
        keyboard = create_category_words_list_menu(
            chat_id=chat_id,
            category='sw',
            page=0,
            total_pages=1
        )

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ callback_data
        callbacks = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                if btn.callback_data:
                    callbacks.append(btn.callback_data)

        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å callback –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è (cf:cwdel –∏–ª–∏ –ø–æ–¥–æ–±–Ω—ã–π)
        has_delete_callback = any(
            'del' in cb.lower() or 'dw' in cb.lower()
            for cb in callbacks
        )

        # –õ–∏–±–æ –∫–Ω–æ–ø–∫–∞ "–£–¥–∞–ª–∏—Ç—å" –¥–æ–ª–∂–Ω–∞ –≤–µ—Å—Ç–∏ –Ω–∞ FSM
        assert len(callbacks) > 0, "–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –¥–æ–ª–∂–Ω–∞ –∏–º–µ—Ç—å callback_data"

    # –¢–µ—Å—Ç: callback –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ FSM
    def test_add_word_fsm_callback_exists(self):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –µ—Å—Ç—å callback –¥–ª—è –∑–∞–ø—É—Å–∫–∞ FSM –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞.

        Callback —Ñ–æ—Ä–º–∞—Ç: cf:{category}w:{chat_id}
        –ì–¥–µ category: sw (simple words), hw (harmful words), ow (obfuscated words)
        """
        from bot.keyboards.content_filter_keyboards import create_category_words_list_menu

        chat_id = -1001234567890
        keyboard = create_category_words_list_menu(
            chat_id=chat_id,
            category='sw',
            page=0,
            total_pages=1
        )

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ callback_data
        callbacks = []
        for row in keyboard.inline_keyboard:
            for btn in row:
                if btn.callback_data:
                    callbacks.append(btn.callback_data)

        # Callback –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤ –∏–º–µ–µ—Ç —Ñ–æ—Ä–º–∞—Ç cf:{category}w:{chat_id}
        # –ù–∞–ø—Ä–∏–º–µ—Ä: cf:sww:-1001234567890 –¥–ª—è simple words
        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω cf:XXw: –≥–¥–µ XX - –∫–æ–¥ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        has_add_callback = any(
            'cf:sww:' in cb or 'cf:hww:' in cb or 'cf:oww:' in cb
            for cb in callbacks
        )

        assert has_add_callback, \
            f"Callback –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω. Callbacks: {callbacks}"


# ============================================================
# –¢–ï–°–¢–´ –î–õ–Ø –ù–û–í–û–ì–û –§–£–ù–ö–¶–ò–û–ù–ê–õ–ê: –ö–ê–¢–ï–ì–û–†–ò–ò, –ó–ê–î–ï–†–ñ–ö–ò, –¢–ï–ö–°–¢
# ============================================================

class TestParseDelaySeconds:
    """–¢–µ—Å—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏ parse_delay_seconds()."""

    def test_parse_seconds_with_s_suffix(self):
        """–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å–µ–∫—É–Ω–¥ —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º 's'."""
        from bot.handlers.content_filter.settings_handler import parse_delay_seconds
        # 30 —Å–µ–∫—É–Ω–¥
        assert parse_delay_seconds("30s") == 30
        # 60 —Å–µ–∫—É–Ω–¥
        assert parse_delay_seconds("60sec") == 60

    def test_parse_minutes_with_min_suffix(self):
        """–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ –º–∏–Ω—É—Ç —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º 'min'."""
        from bot.handlers.content_filter.settings_handler import parse_delay_seconds
        # 5 –º–∏–Ω—É—Ç = 300 —Å–µ–∫—É–Ω–¥
        assert parse_delay_seconds("5min") == 300
        # 1 –º–∏–Ω—É—Ç–∞ = 60 —Å–µ–∫—É–Ω–¥
        assert parse_delay_seconds("1min") == 60

    def test_parse_hours_with_h_suffix(self):
        """–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–∞—Å–æ–≤ —Å —Å—É—Ñ—Ñ–∏–∫—Å–æ–º 'h'."""
        from bot.handlers.content_filter.settings_handler import parse_delay_seconds
        # 1 —á–∞—Å = 3600 —Å–µ–∫—É–Ω–¥
        assert parse_delay_seconds("1h") == 3600
        # 2 —á–∞—Å–∞ = 7200 —Å–µ–∫—É–Ω–¥
        assert parse_delay_seconds("2hour") == 7200

    def test_parse_plain_number_as_seconds(self):
        """–¢–µ—Å—Ç –ø–∞—Ä—Å–∏–Ω–≥–∞ —á–∏—Å–ª–∞ –±–µ–∑ —Å—É—Ñ—Ñ–∏–∫—Å–∞ –∫–∞–∫ —Å–µ–∫—É–Ω–¥—ã."""
        from bot.handlers.content_filter.settings_handler import parse_delay_seconds
        # –ü—Ä–æ—Å—Ç–æ —á–∏—Å–ª–æ = —Å–µ–∫—É–Ω–¥—ã
        assert parse_delay_seconds("45") == 45
        assert parse_delay_seconds("120") == 120

    def test_parse_invalid_format_returns_none(self):
        """–¢–µ—Å—Ç —á—Ç–æ –Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç None."""
        from bot.handlers.content_filter.settings_handler import parse_delay_seconds
        # –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç
        assert parse_delay_seconds("abc") is None
        assert parse_delay_seconds("") is None
        assert parse_delay_seconds("-5s") is None

    def test_parse_case_insensitive(self):
        """–¢–µ—Å—Ç —Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏."""
        from bot.handlers.content_filter.settings_handler import parse_delay_seconds
        # –í–µ—Ä—Ö–Ω–∏–π —Ä–µ–≥–∏—Å—Ç—Ä
        assert parse_delay_seconds("30S") == 30
        assert parse_delay_seconds("5MIN") == 300
        assert parse_delay_seconds("1H") == 3600


class TestFilterResultWithWordCategory:
    """–¢–µ—Å—Ç—ã –¥–ª—è FilterResult —Å –ø–æ–ª–µ–º word_category."""

    def test_filter_result_has_word_category_field(self):
        """–¢–µ—Å—Ç —á—Ç–æ FilterResult –∏–º–µ–µ—Ç –ø–æ–ª–µ word_category."""
        from bot.services.content_filter.filter_manager import FilterResult
        # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–µ–π
        result = FilterResult(
            should_act=True,
            detector_type='word_filter',
            trigger='—Ç–µ—Å—Ç',
            action='mute',
            action_duration=60,
            word_category='harmful'
        )
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é
        assert result.word_category == 'harmful'

    def test_filter_result_word_category_default_none(self):
        """–¢–µ—Å—Ç —á—Ç–æ word_category –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é None."""
        from bot.services.content_filter.filter_manager import FilterResult
        # –°–æ–∑–¥–∞—ë–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        result = FilterResult(
            should_act=True,
            detector_type='scam',
            trigger='—Å–∫–∞–º —Å–∏–≥–Ω–∞–ª'
        )
        # –ö–∞—Ç–µ–≥–æ—Ä–∏—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å None
        assert result.word_category is None


class TestCategoryAdvancedMenuCallbacks:
    """–¢–µ—Å—Ç—ã –¥–ª—è callback –∫–Ω–æ–ø–∫–∏ "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ" –≤ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö."""

    def test_advanced_menu_callback_format(self):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∞ callback –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫."""
        # Callback –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å cf:{category}adv:{chat_id}
        chat_id = -1001234567890
        for category in ['sw', 'hw', 'ow']:
            callback = f"cf:{category}adv:{chat_id}"
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É (–ª–∏–º–∏—Ç 64 –±–∞–π—Ç–∞)
            assert len(callback.encode('utf-8')) <= 64

    def test_mute_text_callback_format(self):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∞ callback –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –º—É—Ç–µ."""
        chat_id = -1001234567890
        for category in ['sw', 'hw', 'ow']:
            callback = f"cf:{category}mt:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64

    def test_ban_text_callback_format(self):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∞ callback –¥–ª—è —Ç–µ–∫—Å—Ç–∞ –ø—Ä–∏ –±–∞–Ω–µ."""
        chat_id = -1001234567890
        for category in ['sw', 'hw', 'ow']:
            callback = f"cf:{category}bt:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64

    def test_delete_delay_callback_format(self):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∞ callback –¥–ª—è –∑–∞–¥–µ—Ä–∂–∫–∏ —É–¥–∞–ª–µ–Ω–∏—è."""
        chat_id = -1001234567890
        for category in ['sw', 'hw', 'ow']:
            callback = f"cf:{category}dd:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64

    def test_notification_delay_callback_format(self):
        """–¢–µ—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∞ callback –¥–ª—è –∞–≤—Ç–æ—É–¥–∞–ª–µ–Ω–∏—è —É–≤–µ–¥–æ–º–ª–µ–Ω–∏—è."""
        chat_id = -1001234567890
        for category in ['sw', 'hw', 'ow']:
            callback = f"cf:{category}nd:{chat_id}"
            assert len(callback.encode('utf-8')) <= 64


class TestCategoryActionMenuHasAdvancedButton:
    """–¢–µ—Å—Ç—ã —á—Ç–æ –º–µ–Ω—é –¥–µ–π—Å—Ç–≤–∏–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–º–µ–µ—Ç –∫–Ω–æ–ø–∫—É '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ'."""

    def test_category_action_menu_has_advanced_button(self):
        """–¢–µ—Å—Ç –Ω–∞–ª–∏—á–∏—è –∫–Ω–æ–ø–∫–∏ '‚öôÔ∏è –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ' –≤ –º–µ–Ω—é –¥–µ–π—Å—Ç–≤–∏–π."""
        from bot.keyboards.content_filter_keyboards import create_category_action_menu

        chat_id = -1001234567890
        for category in ['sw', 'hw', 'ow']:
            keyboard = create_category_action_menu(
                chat_id=chat_id,
                category=category,
                current_action='delete',
                current_duration=None
            )

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –∫–Ω–æ–ø–æ–∫
            button_texts = []
            for row in keyboard.inline_keyboard:
                for btn in row:
                    button_texts.append(btn.text)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–Ω–æ–ø–∫–∏ "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ"
            has_advanced = any('–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ' in text for text in button_texts)
            assert has_advanced, \
                f"–ö–Ω–æ–ø–∫–∞ '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ {category}. –ö–Ω–æ–ø–∫–∏: {button_texts}"


class TestCategoryNotificationSettingsColumns:
    """–¢–µ—Å—Ç—ã –¥–ª—è –Ω–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –Ω–∞—Å—Ç—Ä–æ–µ–∫ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π."""

    def test_model_has_mute_text_columns(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ *_mute_text."""
        from bot.database.models_content_filter import ContentFilterSettings
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        assert hasattr(ContentFilterSettings, 'simple_words_mute_text')
        assert hasattr(ContentFilterSettings, 'harmful_words_mute_text')
        assert hasattr(ContentFilterSettings, 'obfuscated_words_mute_text')

    def test_model_has_ban_text_columns(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ *_ban_text."""
        from bot.database.models_content_filter import ContentFilterSettings
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        assert hasattr(ContentFilterSettings, 'simple_words_ban_text')
        assert hasattr(ContentFilterSettings, 'harmful_words_ban_text')
        assert hasattr(ContentFilterSettings, 'obfuscated_words_ban_text')

    def test_model_has_delete_delay_columns(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ *_delete_delay."""
        from bot.database.models_content_filter import ContentFilterSettings
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        assert hasattr(ContentFilterSettings, 'simple_words_delete_delay')
        assert hasattr(ContentFilterSettings, 'harmful_words_delete_delay')
        assert hasattr(ContentFilterSettings, 'obfuscated_words_delete_delay')

    def test_model_has_notification_delete_delay_columns(self):
        """–¢–µ—Å—Ç —á—Ç–æ –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ *_notification_delete_delay."""
        from bot.database.models_content_filter import ContentFilterSettings
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–æ–ª–æ–Ω–æ–∫
        assert hasattr(ContentFilterSettings, 'simple_words_notification_delete_delay')
        assert hasattr(ContentFilterSettings, 'harmful_words_notification_delete_delay')
        assert hasattr(ContentFilterSettings, 'obfuscated_words_notification_delete_delay')


class TestCategoryTextStatesExist:
    """–¢–µ—Å—Ç—ã –¥–ª—è FSM —Å–æ—Å—Ç–æ—è–Ω–∏–π —Ç–µ–∫—Å—Ç–∞ —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–π."""

    def test_category_text_states_class_exists(self):
        """–¢–µ—Å—Ç —á—Ç–æ –∫–ª–∞—Å—Å CategoryTextStates —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        from bot.handlers.content_filter.settings_handler import CategoryTextStates
        assert CategoryTextStates is not None

    def test_category_text_states_has_mute_text(self):
        """–¢–µ—Å—Ç —á—Ç–æ CategoryTextStates –∏–º–µ–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ waiting_for_mute_text."""
        from bot.handlers.content_filter.settings_handler import CategoryTextStates
        assert hasattr(CategoryTextStates, 'waiting_for_mute_text')

    def test_category_text_states_has_ban_text(self):
        """–¢–µ—Å—Ç —á—Ç–æ CategoryTextStates –∏–º–µ–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ waiting_for_ban_text."""
        from bot.handlers.content_filter.settings_handler import CategoryTextStates
        assert hasattr(CategoryTextStates, 'waiting_for_ban_text')


class TestCategoryDelayStatesExist:
    """–¢–µ—Å—Ç—ã –¥–ª—è FSM —Å–æ—Å—Ç–æ—è–Ω–∏–π –∑–∞–¥–µ—Ä–∂–µ–∫."""

    def test_category_delay_states_class_exists(self):
        """–¢–µ—Å—Ç —á—Ç–æ –∫–ª–∞—Å—Å CategoryDelayStates —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
        from bot.handlers.content_filter.settings_handler import CategoryDelayStates
        assert CategoryDelayStates is not None

    def test_category_delay_states_has_delete_delay(self):
        """–¢–µ—Å—Ç —á—Ç–æ CategoryDelayStates –∏–º–µ–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ waiting_for_delete_delay."""
        from bot.handlers.content_filter.settings_handler import CategoryDelayStates
        assert hasattr(CategoryDelayStates, 'waiting_for_delete_delay')

    def test_category_delay_states_has_notification_delay(self):
        """–¢–µ—Å—Ç —á—Ç–æ CategoryDelayStates –∏–º–µ–µ—Ç —Å–æ—Å—Ç–æ—è–Ω–∏–µ waiting_for_notification_delay."""
        from bot.handlers.content_filter.settings_handler import CategoryDelayStates
        assert hasattr(CategoryDelayStates, 'waiting_for_notification_delay')
