# ============================================================
# TEXT NORMALIZER - НОРМАЛИЗАЦИЯ ТЕКСТА
# ============================================================
# Этот модуль отвечает за нормализацию текста перед проверкой:
# - Замена похожих символов (l33tspeak): 0→о, 1→и, @→а
# - Удаление разделителей между буквами: к-о-к-а → кока
# - Удаление невидимых символов (zero-width)
# - Приведение к нижнему регистру
#
# Это позволяет ловить обфускацию типа: wишki, ko—k-a, eKct-zy
# ============================================================

# Импортируем модуль регулярных выражений для паттернов
import re
# Импортируем unicodedata для работы с Unicode категориями и нормализацией
import unicodedata
# Импортируем тип для аннотаций
from typing import Optional


class TextNormalizer:
    """
    Класс для нормализации текста перед проверкой на запрещённые слова.

    Решает проблему обхода фильтров через:
    - Замену букв на похожие символы (0 вместо о)
    - Вставку разделителей (к-о-к-а-и-н)
    - Использование невидимых символов

    Пример использования:
        normalizer = TextNormalizer()
        normalized = normalizer.normalize("wишki ko—k-a")
        # Результат: "вишки кока"
    """

    # ─────────────────────────────────────────────────────────
    # СЛОВАРЬ ЗАМЕНЫ ПОХОЖИХ СИМВОЛОВ
    # ─────────────────────────────────────────────────────────
    # Ключ = символ который нужно заменить
    # Значение = на что заменяем (кириллица)
    # Включает латиницу, цифры и спецсимволы похожие на буквы
    CHAR_MAP = {
        # Латинские буквы → кириллица (визуально похожие)
        'a': 'а',  # латинская a → кириллическая а
        'b': 'б',  # латинская b → кириллическая б (приблизительно)
        'c': 'с',  # латинская c → кириллическая с
        'd': 'д',  # латинская d → кириллическая д (приблизительно)
        'e': 'е',  # латинская e → кириллическая е
        'f': 'ф',  # латинская f → кириллическая ф (приблизительно)
        'g': 'г',  # латинская g → кириллическая г (приблизительно)
        'h': 'н',  # латинская h → кириллическая н (приблизительно)
        'i': 'и',  # латинская i → кириллическая и
        'k': 'к',  # латинская k → кириллическая к
        'l': 'л',  # латинская l → кириллическая л (приблизительно)
        'm': 'м',  # латинская m → кириллическая м
        'n': 'н',  # латинская n → кириллическая н
        'o': 'о',  # латинская o → кириллическая о
        'p': 'р',  # латинская p → кириллическая р
        'r': 'р',  # латинская r → кириллическая р (приблизительно)
        's': 'с',  # латинская s → кириллическая с (приблизительно)
        't': 'т',  # латинская t → кириллическая т
        'u': 'у',  # латинская u → кириллическая у
        'v': 'в',  # латинская v → кириллическая в (приблизительно)
        'w': 'в',  # латинская w → кириллическая в (часто используется)
        'x': 'х',  # латинская x → кириллическая х
        'y': 'у',  # латинская y → кириллическая у (приблизительно)
        'z': 'з',  # латинская z → кириллическая з (приблизительно)

        # Цифры → буквы (l33tspeak)
        # ВАЖНО: В РУССКОМ l33tspeak цифры заменяют СОГЛАСНЫЕ чаще:
        # 3акладка, 3апрещёнка (3→з)
        '0': 'о',  # ноль похож на букву о
        '1': 'и',  # единица похожа на и (или l→л)
        '3': 'з',  # тройка похожа на з (3акладка → закладка)
        '4': 'а',  # четвёрка похожа на А (з4кладка → закладка)
        '5': 'с',  # пятёрка похожа на s→с
        '6': 'б',  # шестёрка похожа на б (приблизительно)
        '7': 'т',  # семёрка похожа на т (приблизительно)
        '8': 'в',  # восьмёрка похожа на в (или b)
        '9': 'д',  # девятка похожа на д (приблизительно)

        # Спецсимволы → буквы
        '@': 'а',  # собака похожа на а
        '$': 'с',  # доллар похож на s→с
        '€': 'е',  # евро похож на е
        '₽': 'р',  # рубль похож на р
        '!': 'и',  # восклицательный знак иногда заменяет i→и
        '|': 'и',  # вертикальная черта похожа на и или l

        # Заглавные латинские (дополнительно к lower())
        'A': 'а',
        'B': 'б',
        'C': 'с',
        'E': 'е',
        'H': 'н',
        'K': 'к',
        'M': 'м',
        'O': 'о',
        'P': 'р',
        'T': 'т',
        'X': 'х',

        # Small Caps (ᴀᴋᴏ) - NFKD не раскладывает их
        '\u1d00': 'а',  # ᴀ LATIN LETTER SMALL CAPITAL A
        '\u0299': 'б',  # ʙ LATIN LETTER SMALL CAPITAL B
        '\u1d04': 'с',  # ᴄ LATIN LETTER SMALL CAPITAL C
        '\u1d05': 'д',  # ᴅ LATIN LETTER SMALL CAPITAL D
        '\u1d07': 'е',  # ᴇ LATIN LETTER SMALL CAPITAL E
        '\u0262': 'г',  # ɢ LATIN LETTER SMALL CAPITAL G
        '\u029c': 'н',  # ʜ LATIN LETTER SMALL CAPITAL H
        '\u026a': 'и',  # ɪ LATIN LETTER SMALL CAPITAL I
        '\u1d0a': 'й',  # ᴊ LATIN LETTER SMALL CAPITAL J
        '\u1d0b': 'к',  # ᴋ LATIN LETTER SMALL CAPITAL K
        '\u029f': 'л',  # ʟ LATIN LETTER SMALL CAPITAL L
        '\u1d0d': 'м',  # ᴍ LATIN LETTER SMALL CAPITAL M
        '\u0274': 'н',  # ɴ LATIN LETTER SMALL CAPITAL N
        '\u1d0f': 'о',  # ᴏ LATIN LETTER SMALL CAPITAL O
        '\u1d18': 'р',  # ᴘ LATIN LETTER SMALL CAPITAL P
        '\u0280': 'р',  # ʀ LATIN LETTER SMALL CAPITAL R
        '\u1d1b': 'т',  # ᴛ LATIN LETTER SMALL CAPITAL T
        '\u1d1c': 'у',  # ᴜ LATIN LETTER SMALL CAPITAL U
        '\u1d20': 'в',  # ᴠ LATIN LETTER SMALL CAPITAL V
        '\u1d21': 'в',  # ᴡ LATIN LETTER SMALL CAPITAL W
        '\u028f': 'у',  # ʏ LATIN LETTER SMALL CAPITAL Y
        '\u1d22': 'з',  # ᴢ LATIN LETTER SMALL CAPITAL Z

        # ─────────────────────────────────────────────────────────
        # Греческие буквы → кириллица
        # ─────────────────────────────────────────────────────────
        # Спамеры используют греческие буквы похожие на кириллицу:
        # κурьеρ (греческие κ и ρ), вοдитель (греческая ο)
        'α': 'а',  # греческая альфа → кириллическая а
        'β': 'в',  # греческая бета → кириллическая в
        'γ': 'г',  # греческая гамма → кириллическая г
        'δ': 'д',  # греческая дельта → кириллическая д
        'ε': 'е',  # греческая эпсилон → кириллическая е
        'η': 'н',  # греческая эта → кириллическая н
        'ι': 'и',  # греческая йота → кириллическая и
        'κ': 'к',  # греческая каппа → кириллическая к (часто используют!)
        'μ': 'м',  # греческая мю → кириллическая м
        'ν': 'н',  # греческая ню → кириллическая н
        'ο': 'о',  # греческая омикрон → кириллическая о (часто используют!)
        'π': 'п',  # греческая пи → кириллическая п
        'ρ': 'р',  # греческая ро → кириллическая р (часто используют!)
        'σ': 'с',  # греческая сигма → кириллическая с
        'τ': 'т',  # греческая тау → кириллическая т
        'υ': 'у',  # греческая ипсилон → кириллическая у
        'φ': 'ф',  # греческая фи → кириллическая ф
        'χ': 'х',  # греческая хи → кириллическая х
        # Заглавные греческие (на случай если lower() не сработал)
        'Α': 'а',  # заглавная альфа
        'Β': 'в',  # заглавная бета
        'Γ': 'г',  # заглавная гамма
        'Ε': 'е',  # заглавная эпсилон
        'Η': 'н',  # заглавная эта
        'Ι': 'и',  # заглавная йота
        'Κ': 'к',  # заглавная каппа
        'Μ': 'м',  # заглавная мю
        'Ν': 'н',  # заглавная ню
        'Ο': 'о',  # заглавная омикрон
        'Ρ': 'р',  # заглавная ро
        'Τ': 'т',  # заглавная тау
        'Χ': 'х',  # заглавная хи

        # ─────────────────────────────────────────────────────────
        # Negative Squared Latin Letters (🅰-🆉)
        # ─────────────────────────────────────────────────────────
        # Спамеры пишут: 🅼🅴🅵 🅺🅾🅺 (меф кок)
        # NFKD не раскладывает эти символы, добавляем вручную
        '🅰': 'а',  # 🅰 NEGATIVE SQUARED LATIN CAPITAL LETTER A
        '🅱': 'б',  # 🅱 NEGATIVE SQUARED LATIN CAPITAL LETTER B
        '🅲': 'с',  # 🅲 NEGATIVE SQUARED LATIN CAPITAL LETTER C
        '🅳': 'д',  # 🅳 NEGATIVE SQUARED LATIN CAPITAL LETTER D
        '🅴': 'е',  # 🅴 NEGATIVE SQUARED LATIN CAPITAL LETTER E
        '🅵': 'ф',  # 🅵 NEGATIVE SQUARED LATIN CAPITAL LETTER F
        '🅶': 'г',  # 🅶 NEGATIVE SQUARED LATIN CAPITAL LETTER G
        '🅷': 'н',  # 🅷 NEGATIVE SQUARED LATIN CAPITAL LETTER H
        '🅸': 'и',  # 🅸 NEGATIVE SQUARED LATIN CAPITAL LETTER I
        '🅹': 'й',  # 🅹 NEGATIVE SQUARED LATIN CAPITAL LETTER J
        '🅺': 'к',  # 🅺 NEGATIVE SQUARED LATIN CAPITAL LETTER K
        '🅻': 'л',  # 🅻 NEGATIVE SQUARED LATIN CAPITAL LETTER L
        '🅼': 'м',  # 🅼 NEGATIVE SQUARED LATIN CAPITAL LETTER M
        '🅽': 'н',  # 🅽 NEGATIVE SQUARED LATIN CAPITAL LETTER N
        '🅾': 'о',  # 🅾 NEGATIVE SQUARED LATIN CAPITAL LETTER O
        '🅿': 'р',  # 🅿 NEGATIVE SQUARED LATIN CAPITAL LETTER P
        '🆀': 'к',  # 🆀 NEGATIVE SQUARED LATIN CAPITAL LETTER Q
        '🆁': 'р',  # 🆁 NEGATIVE SQUARED LATIN CAPITAL LETTER R
        '🆂': 'с',  # 🆂 NEGATIVE SQUARED LATIN CAPITAL LETTER S
        '🆃': 'т',  # 🆃 NEGATIVE SQUARED LATIN CAPITAL LETTER T
        '🆄': 'у',  # 🆄 NEGATIVE SQUARED LATIN CAPITAL LETTER U
        '🆅': 'в',  # 🆅 NEGATIVE SQUARED LATIN CAPITAL LETTER V
        '🆆': 'в',  # 🆆 NEGATIVE SQUARED LATIN CAPITAL LETTER W
        '🆇': 'х',  # 🆇 NEGATIVE SQUARED LATIN CAPITAL LETTER X
        '🆈': 'у',  # 🆈 NEGATIVE SQUARED LATIN CAPITAL LETTER Y
        '🆉': 'з',  # 🆉 NEGATIVE SQUARED LATIN CAPITAL LETTER Z
    }

    # ─────────────────────────────────────────────────────────
    # ТРАНСЛИТ-ДИГРАФЫ (заменяем ДО отдельных букв)
    # ─────────────────────────────────────────────────────────
    # Спамеры пишут русские слова латиницей (транслит):
    # shishki, marochki, ekstazi, kokain
    # Важно: диграфы заменяются ПЕРВЫМИ, иначе sh → сн (s→с, h→н)
    # Порядок важен: shch перед sh, чтобы "щ" обработалась правильно
    TRANSLIT_DIGRAPHS = [
        # Четырёхбуквенные (первыми!)
        ('shch', 'щ'),   # shchi → щи
        # Трёхбуквенные
        ('sch', 'щ'),    # альтернативное написание щ
        # Двухбуквенные
        ('sh', 'ш'),     # shishki → шишки
        ('ch', 'ч'),     # chay → чай
        ('zh', 'ж'),     # zhena → жена
        ('ts', 'ц'),     # tsvetok → цветок
        ('tz', 'ц'),     # альтернативное написание ц
        ('ya', 'я'),     # ya → я
        ('yu', 'ю'),     # yu → ю
        ('yo', 'ё'),     # yo → ё
        ('ye', 'е'),     # ye → е (в начале слова)
        ('ey', 'ей'),    # альтернатива
        ('iy', 'ий'),    # iy → ий
        ('oy', 'ой'),    # oy → ой
        ('ay', 'ай'),    # ay → ай
        ('uy', 'уй'),    # uy → уй
        ('kh', 'х'),     # kh → х (khлеб)
        ('ph', 'ф'),     # ph → ф (phone)
    ]

    # ─────────────────────────────────────────────────────────
    # СИМВОЛЫ-РАЗДЕЛИТЕЛИ (удаляем)
    # ─────────────────────────────────────────────────────────
    # Эти символы часто вставляют между буквами для обхода фильтра
    # Пример: к-о-к-а-и-н, э.к" с.т" а.з" и
    # ВАЖНО: Пробел НЕ включён! Пробелы между словами должны сохраняться.
    # Для случая "К а з и н о" используется _collapse_spaced_letters().
    SEPARATORS = [
        '-',   # дефис: к-о-к-а
        '–',   # короткое тире
        '—',   # длинное тире
        '_',   # нижнее подчёркивание: ко_ка
        '.',   # точка: к.о.к.а
        ',',   # запятая
        # НЕ добавлять пробел ' ' сюда! Это ломает нормальные предложения.
        '*',   # звёздочка: к*о*к*а
        "'",   # апостроф
        '"',   # кавычки
        '`',   # обратный апостроф
        '~',   # тильда
        '+',   # плюс
        '=',   # равно
        ':',   # двоеточие
        ';',   # точка с запятой
        '/',   # слэш
        '\\',  # обратный слэш
        '|',   # вертикальная черта
        # Block Elements (░▒▓) - часто используются спамерами
        '░',   # U+2591 LIGHT SHADE: ░C░o░c░o
        '▒',   # U+2592 MEDIUM SHADE
        '▓',   # U+2593 DARK SHADE
        '█',   # U+2588 FULL BLOCK
        '▀',   # U+2580 UPPER HALF BLOCK
        '▄',   # U+2584 LOWER HALF BLOCK
        '▌',   # U+258C LEFT HALF BLOCK
        '▐',   # U+2590 RIGHT HALF BLOCK
        # Box Drawing
        '│',   # U+2502 BOX DRAWINGS LIGHT VERTICAL
        '─',   # U+2500 BOX DRAWINGS LIGHT HORIZONTAL
        '┃',   # U+2503 BOX DRAWINGS HEAVY VERTICAL
        '━',   # U+2501 BOX DRAWINGS HEAVY HORIZONTAL
        # Другие декоративные символы
        '•',   # U+2022 BULLET
        '·',   # U+00B7 MIDDLE DOT
        '◦',   # U+25E6 WHITE BULLET
        '○',   # U+25CB WHITE CIRCLE
        '●',   # U+25CF BLACK CIRCLE
        '◯',   # U+25EF LARGE CIRCLE
        '⬤',   # U+2B24 BLACK LARGE CIRCLE
    ]

    # ─────────────────────────────────────────────────────────
    # НЕВИДИМЫЕ СИМВОЛЫ (zero-width)
    # ─────────────────────────────────────────────────────────
    # Эти символы не отображаются, но разбивают слово
    # Используются для обхода фильтров
    INVISIBLE_CHARS = [
        '\u200b',  # Zero Width Space
        '\u200c',  # Zero Width Non-Joiner
        '\u200d',  # Zero Width Joiner
        '\u200e',  # Left-to-Right Mark
        '\u200f',  # Right-to-Left Mark
        '\u2060',  # Word Joiner
        '\u2061',  # Function Application
        '\u2062',  # Invisible Times
        '\u2063',  # Invisible Separator
        '\u2064',  # Invisible Plus
        '\ufeff',  # Byte Order Mark (BOM)
        '\u00ad',  # Soft Hyphen
        '\u034f',  # Combining Grapheme Joiner
        '\u061c',  # Arabic Letter Mark
        '\u115f',  # Hangul Choseong Filler
        '\u1160',  # Hangul Jungseong Filler
        '\u17b4',  # Khmer Vowel Inherent Aq
        '\u17b5',  # Khmer Vowel Inherent Aa
        '\u180e',  # Mongolian Vowel Separator
        '\u2000',  # En Quad (различные виды пробелов)
        '\u2001',  # Em Quad
        '\u2002',  # En Space
        '\u2003',  # Em Space
        '\u2004',  # Three-Per-Em Space
        '\u2005',  # Four-Per-Em Space
        '\u2006',  # Six-Per-Em Space
        '\u2007',  # Figure Space
        '\u2008',  # Punctuation Space
        '\u2009',  # Thin Space
        '\u200a',  # Hair Space
        '\u202f',  # Narrow No-Break Space
        '\u205f',  # Medium Mathematical Space
        '\u3000',  # Ideographic Space
    ]

    def __init__(self):
        """
        Инициализация нормализатора.

        Компилируем регулярные выражения один раз при создании объекта
        для повышения производительности при многократном использовании.
        """
        # Компилируем паттерн для удаления невидимых символов
        # Создаём класс символов [...] из списка
        invisible_pattern = '[' + ''.join(re.escape(c) for c in self.INVISIBLE_CHARS) + ']'
        # Компилируем regex для многократного использования
        self._invisible_regex = re.compile(invisible_pattern)

        # Компилируем паттерн для удаления разделителей между буквами
        # Ищем: буква + разделитель + буква, заменяем на: буква + буква
        separator_chars = ''.join(re.escape(c) for c in self.SEPARATORS)
        # Паттерн: (буква)(один или более разделителей)(буква)
        # \w не подходит идеально, используем Unicode letter categories
        self._separator_regex = re.compile(
            r'(\w)[' + separator_chars + r']+(\w)',
            re.UNICODE
        )

    def normalize(self, text: str) -> str:
        """
        Нормализует текст для сравнения с запрещёнными словами.

        Этапы нормализации:
        1. Приведение к нижнему регистру
        2. Удаление невидимых символов
        3. Удаление разделителей между буквами
        4. Замена похожих символов на кириллицу

        Args:
            text: Исходный текст для нормализации

        Returns:
            Нормализованный текст (нижний регистр, без обфускации)

        Example:
            >>> normalizer = TextNormalizer()
            >>> normalizer.normalize("wИшKi")
            'вишки'
            >>> normalizer.normalize("ko—k-a")
            'кока'
            >>> normalizer.normalize("L s_D")
            'лсд'
        """
        # Проверяем на пустой или None текст
        if not text:
            # Возвращаем пустую строку если входные данные пустые
            return ''

        # ─────────────────────────────────────────────────────────
        # ШАГ 1: NFKD нормализация (раскладка compatibility characters)
        # ─────────────────────────────────────────────────────────
        # Раскладывает специальные Unicode символы в базовые:
        # - ⓚⓞⓚⓐ → koka (enclosed/circled letters)
        # - ｋｏｋａ → koka (fullwidth латиница)
        # - ﬁ → fi (лигатуры)
        # - ² → 2 (надстрочные цифры)
        result = unicodedata.normalize('NFKD', text)

        # ─────────────────────────────────────────────────────────
        # ШАГ 2: Приводим к нижнему регистру
        # ─────────────────────────────────────────────────────────
        # Это упрощает дальнейшее сравнение
        # "КОКАИН" и "кокаин" становятся одинаковыми
        result = result.lower()

        # ─────────────────────────────────────────────────────────
        # ШАГ 3: Удаляем Combining Marks (зачёркивания, подчёркивания, диакритики)
        # ─────────────────────────────────────────────────────────
        # Спамеры используют символы-модификаторы:
        # - U+0336 COMBINING LONG STROKE OVERLAY (зачёркивание: ш̶u̶ш̶к̶u̶)
        # - U+035E COMBINING DOUBLE MACRON (подчёркивание сверху: M͞n͞)
        # - U+035F COMBINING DOUBLE MACRON BELOW (подчёркивание снизу: M͟n͟)
        # - U+0301 COMBINING ACUTE ACCENT (ударение: á)
        #
        # НО! Сначала применяем NFC чтобы сохранить буквы типа й (и + breve)
        # которые NFKD разложил на составляющие.
        # Иначе й превратится в и после удаления combining marks.
        result = unicodedata.normalize('NFC', result)
        #
        # Теперь удаляем все символы категории Mn (Mark, Nonspacing) и Mc (Mark, Spacing Combining)
        # Это уберёт только "декоративные" marks (зачёркивания, подчёркивания),
        # но не те что являются частью букв (они уже скомпозированы в NFC)
        result = ''.join(
            char for char in result
            if unicodedata.category(char) not in ('Mn', 'Mc')
        )

        # ─────────────────────────────────────────────────────────
        # ШАГ 4: Удаляем невидимые символы
        # ─────────────────────────────────────────────────────────
        # Zero-width символы могут разбивать слово:
        # "ко\u200bкаин" выглядит как "кокаин", но не матчится
        result = self._invisible_regex.sub('', result)

        # ─────────────────────────────────────────────────────────
        # ШАГ 5: Заменяем транслит-диграфы
        # ─────────────────────────────────────────────────────────
        # Спамеры пишут русские слова латиницей (транслит):
        # shishki → шишки, marochki → марочки, kokain → кокаин
        # Важно: диграфы заменяются ДО отдельных букв, иначе sh → сн
        for digraph, replacement in self.TRANSLIT_DIGRAPHS:
            result = result.replace(digraph, replacement)

        # ─────────────────────────────────────────────────────────
        # ШАГ 6: Заменяем похожие символы на кириллицу
        # ─────────────────────────────────────────────────────────
        # "wишki" → "вишки"
        # "k0ka" → "кока"
        # ВАЖНО: делаем ДО удаления разделителей, чтобы k-@-n → к-а-н
        normalized_chars = []
        for char in result:
            # Если символ есть в словаре замен - заменяем
            if char in self.CHAR_MAP:
                normalized_chars.append(self.CHAR_MAP[char])
            else:
                # Иначе оставляем как есть
                normalized_chars.append(char)

        # Собираем обратно в строку
        result = ''.join(normalized_chars)

        # ─────────────────────────────────────────────────────────
        # ШАГ 7: Удаляем разделители между буквами
        # ─────────────────────────────────────────────────────────
        # "к-о-к-а" → "кока"
        # Теперь все символы уже кириллица, разделители корректно удалятся
        prev_result = None
        # Повторяем пока есть изменения (максимум 10 итераций для защиты)
        iterations = 0
        while prev_result != result and iterations < 10:
            # Сохраняем предыдущий результат для сравнения
            prev_result = result
            # Заменяем: буква + разделители + буква → буква + буква
            result = self._separator_regex.sub(r'\1\2', result)
            # Увеличиваем счётчик итераций
            iterations += 1

        # ─────────────────────────────────────────────────────────
        # ШАГ 8: Удаляем пробелы между одиночными буквами
        # ─────────────────────────────────────────────────────────
        # Обрабатываем случай "К а з и н о" → "Казино"
        # Паттерн: если слово состоит из букв разделённых пробелами
        # и каждая "буква" - это одиночный символ
        result = self._collapse_spaced_letters(result)

        # ─────────────────────────────────────────────────────────
        # ШАГ 8.1: Схлопываем повторяющиеся буквы (ПЕРЕД проверкой длины)
        # ─────────────────────────────────────────────────────────
        # Важно сделать ДО ШАГ 8.2, чтобы "лооооо" стало "ло" (2 буквы)
        # и прошло проверку {1,4} в ШАГ 8.2
        result = re.sub(r'(.)\1+', r'\1', result)

        # ─────────────────────────────────────────────────────────
        # ШАГ 8.2: Убираем пробелы вокруг разделителей для КОРОТКИХ слов
        # ─────────────────────────────────────────────────────────
        # "шиш - ло" → "шишло"
        # НО "добрый - день" остаётся как есть (длинные слова)
        # Паттерн: короткое слово (1-4 буквы) + пробел-разделитель-пробел + короткое слово
        # Применяем несколько раз для цепочек типа "ши - ш - ло"
        for _ in range(5):
            prev = result
            # \b гарантирует что мы не захватываем часть длинного слова
            result = re.sub(
                r'\b([а-яёa-z]{1,4})\s*[-.,_*:;]+\s*([а-яёa-z]{1,4})\b',
                r'\1\2',
                result,
                flags=re.IGNORECASE
            )
            if result == prev:
                break

        # ─────────────────────────────────────────────────────────
        # ШАГ 8.3: Повторно удаляем разделители
        # ─────────────────────────────────────────────────────────
        # После схлопывания букв могут остаться разделители:
        # "шиш-ло" → "шишло"
        prev_result = None
        iterations = 0
        while prev_result != result and iterations < 5:
            prev_result = result
            result = self._separator_regex.sub(r'\1\2', result)
            iterations += 1

        # Возвращаем нормализованный текст
        return result

    def _collapse_spaced_letters(self, text: str) -> str:
        """
        Схлопывает пробелы и разделители между одиночными буквами.

        Обрабатывает обфускацию типа:
        - "К а з и н о" → "казино"
        - "ш и - ш - л - о" → "шишло"
        - "к о - к - а" → "кока"

        Args:
            text: Текст для обработки

        Returns:
            Текст со схлопнутыми буквами
        """
        # Паттерн: находим последовательности одиночных букв разделённых
        # пробелами и/или разделителями (-, ., _, и т.д.)
        # Минимум 3 буквы подряд чтобы не ломать нормальный текст
        # Разделители: пробелы, дефисы, точки, подчёркивания и т.д.
        sep = r'[\s\-\.\,\_\*\:\;\|\~\+\=\/\\]+'
        # Ищем: буква + (разделитель + буква){2,} — минимум 3 буквы
        spaced_pattern = re.compile(
            rf'\b([а-яёa-z\d])(?:{sep}([а-яёa-z\d])){{2,}}\b',
            re.IGNORECASE | re.UNICODE
        )

        def replace_spaced(match):
            # Извлекаем все буквы из совпавшего текста
            # match.group(0) = полный матч, например "ш и - ш - л - о"
            letters = re.findall(r'[а-яёa-z\d]', match.group(0), re.IGNORECASE)
            return ''.join(letters)

        # Применяем замену несколько раз для вложенных случаев
        prev = None
        iterations = 0
        while prev != text and iterations < 5:
            prev = text
            text = spaced_pattern.sub(replace_spaced, text)
            iterations += 1

        return text

    def normalize_word(self, word: str) -> str:
        """
        Нормализует отдельное слово (без пробелов).

        Отличие от normalize(): убирает ВСЕ пробелы,
        а не только между буквами.

        Args:
            word: Слово для нормализации

        Returns:
            Нормализованное слово без пробелов
        """
        # Убираем все пробелы из слова
        word_no_spaces = word.replace(' ', '')
        # Применяем стандартную нормализацию
        return self.normalize(word_no_spaces)

    def get_words_from_text(self, text: str) -> list[str]:
        """
        Извлекает отдельные слова из текста после нормализации.

        Полезно для проверки каждого слова по отдельности.

        Args:
            text: Исходный текст

        Returns:
            Список нормализованных слов

        Example:
            >>> normalizer = TextNormalizer()
            >>> normalizer.get_words_from_text("Привет wишki!")
            ['привет', 'вишки']
        """
        # Сначала нормализуем весь текст
        normalized = self.normalize(text)
        # Разбиваем по не-буквенным символам
        # \W+ означает один или более не-словесных символов
        words = re.split(r'\W+', normalized, flags=re.UNICODE)
        # Фильтруем пустые строки
        return [w for w in words if w]


# ============================================================
# ГЛОБАЛЬНЫЙ ЭКЗЕМПЛЯР ДЛЯ ПЕРЕИСПОЛЬЗОВАНИЯ
# ============================================================
# Создаём один экземпляр нормализатора для всего приложения
# Это экономит память и время на компиляцию regex
_normalizer_instance: Optional[TextNormalizer] = None


def get_normalizer() -> TextNormalizer:
    """
    Возвращает глобальный экземпляр TextNormalizer.

    Использует паттерн Singleton для переиспользования.

    Returns:
        TextNormalizer: Глобальный экземпляр нормализатора
    """
    global _normalizer_instance
    # Создаём экземпляр только при первом вызове
    if _normalizer_instance is None:
        _normalizer_instance = TextNormalizer()
    return _normalizer_instance
